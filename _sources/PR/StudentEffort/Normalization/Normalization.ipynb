{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "\n",
    "![normalization](../Normalization/photo_6046321558080833561_y.jpg)\n",
    "\n",
    "\n",
    "Data normalization is a crucial step in data preprocessing in order to standardize and scale data values across various ranges. This helps improve the performance and accuracy of machine learning models. Here are several different methods of normalization, each suited for different scenarios:\n",
    "## 1. Min-Max Normalization\n",
    "Min-Max normalization scales data to a specified range, typically [0, 1]. The formula is:\n",
    "\n",
    "\\[\n",
    "X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "\\]\n",
    "\n",
    "- **Key Features**:\n",
    "  - Ideal for data that is uniformly distributed.\n",
    "  - Useful when data needs to be constrained within a specific range.\n",
    "\n",
    "## 2. Z-Score Normalization (Standardization)\n",
    "This method normalizes data by subtracting the mean and dividing by the standard deviation, making the data have a mean of 0 and a standard deviation of 1:\n",
    "\n",
    "\\[\n",
    "X' = \\frac{X - \\mu}{\\sigma}\n",
    "\\]\n",
    "\n",
    "- **Key Features**:\n",
    "  - Suitable for data with a normal distribution.\n",
    "  - Effective for data with varying means and variances.\n",
    "\n",
    "## 3. Decimal Scaling\n",
    "Decimal scaling normalizes data by moving the decimal point of the data values, ensuring they fall within a specific range. The formula is:\n",
    "\n",
    "\\[\n",
    "X' = \\frac{X}{10^j}\n",
    "\\]\n",
    "\n",
    "Where \\( j \\) is the number of digits of the largest absolute value.\n",
    "\n",
    "- **Key Features**:\n",
    "  - Useful for data with values that vary across several orders of magnitude.\n",
    "\n",
    "## 4. Max Abs Normalization\n",
    "This method normalizes data by dividing each value by the maximum absolute value, ensuring data lies within the range [-1, 1]:\n",
    "\n",
    "\\[\n",
    "X' = \\frac{X}{|X_{\\text{max}}|}\n",
    "\\]\n",
    "\n",
    "- **Key Features**:\n",
    "  - Suitable for data with both positive and negative values.\n",
    "\n",
    "## 5. Robust Scaler\n",
    "The robust scaler normalizes data by using the median and interquartile range (IQR):\n",
    "\n",
    "\\[\n",
    "X' = \\frac{X - \\text{median}}{\\text{IQR}}\n",
    "\\]\n",
    "\n",
    "- **Key Features**:\n",
    "  - Useful for data with outliers.\n",
    "  - Reduces the impact of extreme values.\n",
    "\n",
    "## 6. Log Transformation\n",
    "Log transformation applies the logarithm function to data values, reducing large differences in data scale:\n",
    "\n",
    "\\[\n",
    "X' = \\log(X + 1)\n",
    "\\]\n",
    "\n",
    "- **Key Features**:\n",
    "  - Suitable for data with non-normal distributions or large differences in values.\n",
    "  - Commonly used for financial data or very large numbers.\n",
    "\n",
    "## 7. Power Transformation\n",
    "This method applies power functions like Box-Cox or Yeo-Johnson transformations to normalize data:\n",
    "\n",
    "- **Key Features**:\n",
    "  - Useful for data that doesn’t improve with log or square root transformations.\n",
    "  - Helps in normalizing non-Gaussian distributions.\n",
    "\n",
    "## 8. L2 Normalization\n",
    "In L2 normalization, the data vector is scaled such that the vector’s length equals 1. The formula is:\n",
    "\n",
    "\\[\n",
    "X' = \\frac{X}{\\|X\\|}\n",
    "\\]\n",
    "\n",
    "- **Key Features**:\n",
    "  - Effective for algorithms like KNN or SVM that rely on distances between data points.\n",
    "\n",
    "### Conclusion\n",
    "Choosing the right normalization method depends on the characteristics of the data and the algorithm being used. Proper normalization can lead to significant improvements in model performance by ensuring that features contribute equally to the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization Methods\n",
    "\n",
    "In this example, we apply various normalization techniques on a dataset. The methods used are:\n",
    "1. **Min-Max Normalization**: Scales the data between 0 and 1.\n",
    "2. **Z-Score Normalization**: Standardizes the data with mean 0 and standard deviation 1.\n",
    "3. **Robust Scaler**: Uses the median and IQR for scaling.\n",
    "4. **L2 Normalization**: Scales the vector length to 1.\n",
    "\n",
    "Below is the Python code to apply these methods on an example dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'Feature1': [200, 300, 400, 500, 600],\n",
    "    'Feature2': [20, 30, 10, 40, 25],\n",
    "    'Feature3': [5, 10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Min-Max Normalization\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_normalized = min_max_scaler.fit_transform(df)\n",
    "\n",
    "# Z-Score Normalization (Standardization)\n",
    "zscore_scaler = StandardScaler()\n",
    "zscore_normalized = zscore_scaler.fit_transform(df)\n",
    "\n",
    "# Robust Scaler Normalization\n",
    "robust_scaler = RobustScaler()\n",
    "robust_normalized = robust_scaler.fit_transform(df)\n",
    "\n",
    "# L2 Normalization\n",
    "l2_normalizer = Normalizer(norm='l2')\n",
    "l2_normalized = l2_normalizer.fit_transform(df)\n",
    "\n",
    "# Convert all normalizations into a DataFrame for comparison\n",
    "normalized_data = pd.DataFrame({\n",
    "    'Original Feature1': df['Feature1'],\n",
    "    'Original Feature2': df['Feature2'],\n",
    "    'Original Feature3': df['Feature3'],\n",
    "    'MinMax Feature1': min_max_normalized[:, 0],\n",
    "    'ZScore Feature1': zscore_normalized[:, 0],\n",
    "    'Robust Feature1': robust_normalized[:, 0],\n",
    "    'L2 Feature1': l2_normalized[:, 0]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "normalized_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization Results\n",
    "\n",
    "Below is the result of applying different normalization methods to the first feature of the dataset:\n",
    "\n",
    "- **Min-Max Normalization**: Transforms the data into a range between 0 and 1.\n",
    "- **Z-Score Normalization**: Standardizes the data with mean 0 and standard deviation 1.\n",
    "- **Robust Scaler**: Minimizes the influence of outliers by using the median and interquartile range.\n",
    "- **L2 Normalization**: Scales the vector so that its length equals 1.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
