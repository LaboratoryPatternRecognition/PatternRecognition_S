
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Linkage Clustering Algorithm &#8212; Dr.Hadi Sadoghi Yazdi</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'PR/StudentEffort/LinkageClustering1/linkageclustering2';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Word2Vec" href="../Word2Vec/Word2Vec.html" />
    <link rel="prev" title="GloVe: Word Representation" href="../GloVe/GloVe1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../pattern_recognition.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/Hadi_Sadoghi_Yazdi.png" class="logo__image only-light" alt="Dr.Hadi Sadoghi Yazdi - Home"/>
    <script>document.write(`<img src="../../../_static/Hadi_Sadoghi_Yazdi.png" class="logo__image only-dark" alt="Dr.Hadi Sadoghi Yazdi - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../pattern_recognition.html">
                    Pattern Recognition
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction of PR</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/PR_intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/DataSet.html">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/Model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/Cost.html">Cost_Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/LearningRule.html">Learning_Rule</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Visualization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Visualization/PR_intro_Visualization.html">Visualization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Clustering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/PR_intro_Clustering.html">Clustering Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/Clustering_1.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/FCM_1.html">k-means and fuzzy-c-means clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/FCM_Saghi_Project.html">Complementary of FCM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/LinkageClustering_1.html">Project Linkage clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/e_insensitive_linkage.html">Project <span class="math notranslate nohighlight">\( \epsilon \)</span> -insensitive Linkage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/SOFM_Project.html">Project Title: Self-Organizing Feature Map (SOFM)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Regression</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Introduction_Regression.html">Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Regression_1.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/NonLinearRegression.html">Non-linear Regression: The starting point</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Linearization.html">Linearization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Kernel_for_Regression.html">Kernel method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/EvaluationModelSelection.html">Project : Evaluation and Model Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Solution_for_Regression.html">Solution Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/TheoryRegression.html">Theoretical Aspects of Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/ApplicationsPatternRecognition.html">Applications in Pattern Recognition</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Classification</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Classification/PR_intro_Classification.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/SVDD.html">Support Vector Data Description (SVDD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/SVM1.html">Support Vector Machine (SVM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/Fisherclassifier.html">Fihser Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/KernelFisherDiscriminantAnalysis.html">Kernel Fisher Discriminant Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/DecisionTree1.html">Project Induction in Decision Trees</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">BayesEstimation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/BayesEstimation.html">Bayes Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/KDE_1.html">kernel-based density estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/MeanShift.html">Mean Shift Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/ParametricDensityEstimation1.html">Parametric Density Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/GMM.html">Gaussian Mixture Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Student Effort</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Whyprojection1.html">What is Projection?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Star%20Coordinates/Star_Coordinates.html">Star Coordinates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Covariance_Fekri/Covariance_Poorya.html">Covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear-least-square-final/least-square.html">Linear Least Square Method</a></li>






<li class="toctree-l1"><a class="reference internal" href="../ECG/ecg.html">ECG: Measurement of heart rate and probability of heart attack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../correntropy/correntropy.html">Understanding Correntropy as a Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Normalization/Normalization_1.html">Data Normalization</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Chernoff/ChernoffEsri.html">Chernoff Faces in ESRI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GloVe/GloVe1.html">GloVe: Word Representation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Linkage Clustering Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Word2Vec/Word2Vec.html">Word2Vec</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supplementary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/Supplementary1.html">Supplementary Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/EVD.html">Eigen Value Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/twin_svm.html">Twin SVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/Covariance1.html">Covariance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Contact</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../Contact_Me.html">Contact Me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../About_Me.html">About Me</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/h-sadoghi/dr-sadoghi.git" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/h-sadoghi/dr-sadoghi.git/issues/new?title=Issue%20on%20page%20%2FPR/StudentEffort/LinkageClustering1/linkageclustering2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/PR/StudentEffort/LinkageClustering1/linkageclustering2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Linkage Clustering Algorithm</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-clustering">1. Basics of Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-of-clustering">Definition of Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-clustering">Types of Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-clutering-and-regression-and-classification"><strong>Difference between Clutering and Regression and Classification</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise  :</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-clustering">2. Hierarchical Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-of-hierarchical-clustering">Definition of Hierarchical Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-clustering-bottom-up">Agglomerative Clustering (Bottom-Up)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#divisive-clustering-top-down">Divisive Clustering (Top-Down)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dendrograms">Dendrograms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distance-measures">3. Distance Measures</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#euclidean-distance">Euclidean Distance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#manhattan-distance">Manhattan Distance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-distance-metrics">Other Distance Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#minkowski-distance">Minkowski Distance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-similarity">Cosine Similarity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hamming-distance">Hamming Distance</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linkage-criteria">4. Linkage Criteria</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-linkage">Single Linkage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-linkage">Complete Linkage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#average-linkage">Average Linkage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ward-s-method">Ward’s Method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#derivation-of-ward-s-method">Derivation of Ward’s Method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-of-different-linkage-criterias-in-python">Implementation of different Linkage criterias in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm-steps">5. Algorithm Steps</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-procedure">Step-by-Step Procedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-linkage-method"><strong>1. Complete Linkage Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-solution"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-initial-distance-matrix"><strong>Step 1: Initial Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-initialize-clusters"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-first-merge"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-complete-linkage"><strong>Step 4: Update the Distance Matrix (Complete Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-second-merge"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-complete-linkage"><strong>Step 6: Update the Distance Matrix (Complete Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-7-final-merge"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-linkage-method"><strong>2. Single Linkage Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-compute-the-initial-distance-matrix"><strong>Step 1: Compute the Initial Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-single-linkage"><strong>Step 4: Update the Distance Matrix (Single Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-single-linkage"><strong>Step 6: Update the Distance Matrix (Single Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#average-linkage-method"><strong>3. Average Linkage Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10"><strong>Step 1: Compute the Initial Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id11"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-average-linkage"><strong>Step 4: Update the Distance Matrix (Average Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id13"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-average-linkage"><strong>Step 6: Update the Distance Matrix (Average Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id14"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15"><strong>4. Ward’s Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id16"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-ward-s-method-calculations"><strong>Understanding Ward’s Method Calculations</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-compute-the-initial-ward-s-distance-matrix"><strong>Step 1: Compute the Initial Ward’s Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id17"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id18"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-ward-s-method"><strong>Step 4: Update the Distance Matrix (Ward’s Method)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id19"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-ward-s-method"><strong>Step 6: Update the Distance Matrix (Ward’s Method)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id20"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-merges-for-each-method"><strong>Summary of Merges for Each Method</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-single-linkage-clustering-implementation-in-python-step-by-step-explanation">Agglomerative Single Linkage Clustering Implementation in Python (Step by step explanation)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#importing-required-libraries">1. Importing Required Libraries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-load-the-data-into-a-dataframe">2. Step 1: Load the Data into a DataFrame</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-initial-data-points">3. Plot Initial Data Points</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-compute-the-linkage-matrix">4. Step 2: Compute the Linkage Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialize-clusters">5. Initialize Clusters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#function-to-plot-clusters">6. Function to Plot Clusters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#function-to-plot-dendrogram">7. Function to Plot Dendrogram</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-perform-agglomerative-clustering">8. Step 3: Perform Agglomerative Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-final-clusters">9. Step 4: Final Clusters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-single-linkage-clustering-implementation-in-python-full-code">Agglomerative Single Linkage Clustering Implementation in Python (Full code)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#refrences">Refrences</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="linkage-clustering-algorithm">
<h1>Linkage Clustering Algorithm<a class="headerlink" href="#linkage-clustering-algorithm" title="Link to this heading">#</a></h1>
<p><img alt="Mustafa" src="../../../_images/img3.jpg" /></p>
<ul class="simple">
<li><p><strong>Auther : Mustafa Sadeghi</strong></p></li>
<li><p><strong>E-mail : <a class="reference external" href="mailto:mustafasadeghi&#37;&#52;&#48;mail&#46;um&#46;ac&#46;ir">mustafasadeghi<span>&#64;</span>mail<span>&#46;</span>um<span>&#46;</span>ac<span>&#46;</span>ir</a></strong></p></li>
</ul>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>Welcome to this detailed lecture on <strong>Linkage Clustering</strong>, a fundamental technique in hierarchical clustering within unsupervised machine learning. Clustering aims to group data points such that those within the same cluster are more similar to each other than to those in other clusters.</p>
<p>This lecture will cover:</p>
<ul class="simple">
<li><p>Fundamental concepts and definitions in clustering.</p></li>
<li><p>Detailed explanations of hierarchical clustering methods.</p></li>
<li><p>Comprehensive coverage of distance measures.</p></li>
<li><p>In-depth discussion of linkage criteria with mathematical derivations.</p></li>
<li><p>Step-by-step algorithmic procedures.</p></li>
<li><p>Numerical exercises with solutions.</p></li>
<li><p>Practical implementation using Python code.</p></li>
</ul>
</section>
<section id="basics-of-clustering">
<h2>1. Basics of Clustering<a class="headerlink" href="#basics-of-clustering" title="Link to this heading">#</a></h2>
<section id="definition-of-clustering">
<h3>Definition of Clustering<a class="headerlink" href="#definition-of-clustering" title="Link to this heading">#</a></h3>
<p><strong>Clustering</strong> is the task of partitioning a set of data points into groups (clusters) such that:</p>
<ul class="simple">
<li><p><strong>Intra-cluster similarity</strong> is high: Data points within the same cluster are similar.</p></li>
<li><p><strong>Inter-cluster similarity</strong> is low: Data points from different clusters are dissimilar.</p></li>
</ul>
<p><strong>Mathematically</strong>, given a dataset <span class="math notranslate nohighlight">\( X = \{x_1, x_2, \dots, x_n\} \)</span>, the goal is to partition <span class="math notranslate nohighlight">\( X \)</span> into <span class="math notranslate nohighlight">\( k \)</span> clusters <span class="math notranslate nohighlight">\( C = \{C_1, C_2, \dots, C_k\} \)</span> such that:</p>
<ul class="simple">
<li><p><strong>Completeness</strong>: <span class="math notranslate nohighlight">\( \bigcup_{i=1}^k C_i = X \)</span></p></li>
<li><p><strong>Exclusive Membership</strong>: <span class="math notranslate nohighlight">\( C_i \cap C_j = \emptyset \)</span> for all <span class="math notranslate nohighlight">\( i \neq j \)</span></p></li>
</ul>
</section>
<section id="types-of-clustering">
<h3>Types of Clustering<a class="headerlink" href="#types-of-clustering" title="Link to this heading">#</a></h3>
<p>There are many categories and types of clustering, as well as clustering algorithms. I have prepared a table for you to provide an overview, and I will explain some of them. If you are interested in more information, you can visit the following links :</p>
<ul class="simple">
<li><p><a class="reference external" href="https://developers.google.com/machine-learning/clustering/clustering-algorithms">Clustering algorithms by Google developers</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/article/10.1007/s40745-015-0040-1">A Comprehensive Survey of Clustering Algorithms by SPRINGER</a></p></li>
</ul>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Clustering Type</p></th>
<th class="head"><p>Algorithms</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Partitioning Methods</strong></p></td>
<td><p>K-means, K-medoids, PAM (Partitioning Around Medoids), CLARA (Clustering Large Applications)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hierarchical Methods</strong></p></td>
<td><p>Agglomerative clustering, Divisive clustering, BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), CURE (Clustering Using Representatives)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Density-based Methods</strong></p></td>
<td><p>DBSCAN (Density-Based Spatial Clustering of Applications with Noise), OPTICS (Ordering Points To Identify the Clustering Structure), MeanShift</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Grid-based Methods</strong></p></td>
<td><p>STING (Statistical Information Grid), CLIQUE (Clustering In QUEst), WaveCluster</p></td>
</tr>
<tr class="row-even"><td><p><strong>Model-based Methods</strong></p></td>
<td><p>EM (Expectation-Maximization), Gaussian Mixture Models, COBWEB, SOM (Self-Organizing Map)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Fuzzy Clustering</strong></p></td>
<td><p>Fuzzy C-means, Gustafson–Kessel (GK) algorithm</p></td>
</tr>
<tr class="row-even"><td><p><strong>Spectral Clustering</strong></p></td>
<td><p>Normalized cuts, Ratio cuts, Multilevel graph partitioning methods</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Subspace Clustering</strong></p></td>
<td><p>PROCLUS (Projected Clustering), CLIQUE, SUBCLU</p></td>
</tr>
<tr class="row-even"><td><p><strong>Constraint-based Clustering</strong></p></td>
<td><p>COP-KMeans (Constrained K-Means), Seeded K-Means</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Neural Network-based Clustering</strong></p></td>
<td><p>Self-Organizing Maps (SOM), Neural Gas Algorithm, Autoencoder-based Clustering</p></td>
</tr>
<tr class="row-even"><td><p><strong>Deep Clustering</strong></p></td>
<td><p>Deep Embedding Clustering (DEC), Variational Deep Embedding (VaDE)</p></td>
</tr>
</tbody>
</table>
</div>
<ol class="arabic simple">
<li><p><strong>Partitioning Methods</strong>:</p>
<ul class="simple">
<li><p><strong>Definition</strong>: Techniques that divide data into non-overlapping subsets (clusters) such that each data point belongs to exactly one cluster.</p></li>
<li><p><strong>Examples</strong>: K-means clustering, K-medoids.</p></li>
</ul>
</li>
<li><p><strong>Hierarchical Methods</strong>:</p>
<ul class="simple">
<li><p><strong>Definition</strong>: Techniques that create a hierarchy of clusters, represented as a tree (dendrogram).</p></li>
<li><p><strong>Subtypes</strong>:</p>
<ul>
<li><p><strong>Agglomerative Clustering (Bottom-Up)</strong>: Builds the hierarchy by successively merging smaller clusters.</p></li>
<li><p><strong>Divisive Clustering (Top-Down)</strong>: Builds the hierarchy by successively splitting larger clusters.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Density-Based Methods</strong>:</p>
<ul class="simple">
<li><p><strong>Definition</strong>: Techniques that identify clusters as dense regions in the data space, separated by regions of lower density.</p></li>
<li><p><strong>Examples</strong>: DBSCAN, OPTICS.</p></li>
</ul>
</li>
<li><p><strong>Model-Based Methods</strong>:</p>
<ul class="simple">
<li><p><strong>Definition</strong>: Techniques that assume the data is generated by a mixture of underlying probability distributions (models).</p></li>
<li><p><strong>Examples</strong>: Gaussian Mixture Models (GMM).</p></li>
</ul>
</li>
</ol>
<p>Clustering helps in understanding the natural grouping within data without prior knowledge of class labels. It is widely used in exploratory data analysis, pattern recognition, image processing, and bioinformatics.</p>
<p><strong>Key Considerations</strong>:</p>
<ul class="simple">
<li><p><strong>Similarity Measures</strong>: Essential for determining how data points are grouped.</p></li>
<li><p><strong>Number of Clusters</strong>: Determining the optimal number of clusters is often challenging and may require domain knowledge or methods like the elbow method or silhouette analysis.</p></li>
<li><p><strong>Scalability</strong>: Clustering algorithms should handle large datasets efficiently.</p></li>
</ul>
</section>
<section id="difference-between-clutering-and-regression-and-classification">
<h3><strong>Difference between Clutering and Regression and Classification</strong><a class="headerlink" href="#difference-between-clutering-and-regression-and-classification" title="Link to this heading">#</a></h3>
<p>In classification and regression models, we are given a data set(D) which contains data points(Xi) and class labels(Yi). Where, Yi’s belong to {0,1} or {0,1,2,…,n) for Classification models and Yi’s belong to real values for regression models.
When it comes to clustering, we’re provided with a data set that contains only data points(Xi). Here we’re not provided with the class labels(Yi).</p>
</section>
<section id="exercise">
<h3>Exercise  :<a class="headerlink" href="#exercise" title="Link to this heading">#</a></h3>
<p><strong>Dataset</strong>:</p>
<p>Consider the following data points in 2D space:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
x_1 &amp;= (1, 2) \\
x_2 &amp;= (2, 1) \\
x_3 &amp;= (4, 5) \\
x_4 &amp;= (5, 4) \\
\end{align*}
\end{split}\]</div>
<p><strong>Exercise</strong>:</p>
<ul class="simple">
<li><p><strong>Question</strong>: Visually inspect and suggest how to cluster these points into two clusters. Provide a brief explanation.</p></li>
</ul>
<p><strong>Solution</strong>:</p>
<ul class="simple">
<li><p><strong>Visualization</strong>:</p>
<ul>
<li><p>Plotting the points, we observe that <span class="math notranslate nohighlight">\( x_1 \)</span> and <span class="math notranslate nohighlight">\( x_2 \)</span> are close to each other in the lower-left region.</p></li>
<li><p><span class="math notranslate nohighlight">\( x_3 \)</span> and <span class="math notranslate nohighlight">\( x_4 \)</span> are close to each other in the upper-right region.</p></li>
</ul>
</li>
<li><p><strong>Clustering</strong>:</p>
<ul>
<li><p><strong>Cluster 1</strong>: <span class="math notranslate nohighlight">\( x_1 \)</span> and <span class="math notranslate nohighlight">\( x_2 \)</span></p></li>
<li><p><strong>Cluster 2</strong>: <span class="math notranslate nohighlight">\( x_3 \)</span> and <span class="math notranslate nohighlight">\( x_4 \)</span></p></li>
</ul>
</li>
<li><p><strong>Explanation</strong>:</p>
<ul>
<li><p>The spatial proximity suggests two natural groupings based on the positions of the data points.</p></li>
</ul>
</li>
</ul>
<p><strong>Answer</strong>:</p>
<ul class="simple">
<li><p><strong>Cluster 1</strong>: <span class="math notranslate nohighlight">\( x_1 = (1, 2) \)</span>, <span class="math notranslate nohighlight">\( x_2 = (2, 1) \)</span></p></li>
<li><p><strong>Cluster 2</strong>: <span class="math notranslate nohighlight">\( x_3 = (4, 5) \)</span>, <span class="math notranslate nohighlight">\( x_4 = (5, 4) \)</span></p></li>
</ul>
</section>
</section>
<section id="hierarchical-clustering">
<h2>2. Hierarchical Clustering<a class="headerlink" href="#hierarchical-clustering" title="Link to this heading">#</a></h2>
<section id="definition-of-hierarchical-clustering">
<h3>Definition of Hierarchical Clustering<a class="headerlink" href="#definition-of-hierarchical-clustering" title="Link to this heading">#</a></h3>
<p><strong>Hierarchical Clustering</strong> is a method of cluster analysis which seeks to build a hierarchy of clusters. It results in a tree-like structure called a dendrogram, which represents the nested grouping of patterns and the levels at which groupings change.</p>
</section>
<section id="agglomerative-clustering-bottom-up">
<h3>Agglomerative Clustering (Bottom-Up)<a class="headerlink" href="#agglomerative-clustering-bottom-up" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>Agglomerative clustering is a type of hierarchical clustering that builds the dendrogram from the bottom up.</p>
<ul class="simple">
<li><p><strong>Process</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Initialization</strong>: Start with ( n ) singleton clusters (each data point is its own cluster).</p></li>
<li><p><strong>Iteration</strong>:</p>
<ul>
<li><p><strong>Compute Proximities</strong>: Calculate the distance between all pairs of clusters using a chosen linkage criterion.</p></li>
<li><p><strong>Merge Clusters</strong>: Identify and merge the two closest clusters.</p></li>
<li><p><strong>Update Proximities</strong>: Recalculate distances between the new cluster and all other clusters.</p></li>
</ul>
</li>
<li><p><strong>Termination</strong>: Continue until all data points are merged into a single cluster.</p></li>
</ol>
</li>
</ul>
</section>
<section id="divisive-clustering-top-down">
<h3>Divisive Clustering (Top-Down)<a class="headerlink" href="#divisive-clustering-top-down" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>Divisive clustering is a hierarchical clustering method that builds the dendrogram from the top down.</p>
<ul class="simple">
<li><p><strong>Process</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Initialization</strong>: Start with all data points in a single cluster.</p></li>
<li><p><strong>Iteration</strong>:</p>
<ul>
<li><p><strong>Split Clusters</strong>: At each step, the algorithm splits clusters based on a criterion (e.g., maximizing between-cluster dissimilarity).</p></li>
<li><p><strong>Update Clusters</strong>: Recalculate the clustering structure after each split.</p></li>
</ul>
</li>
<li><p><strong>Termination</strong>: Continue until each data point is in its own singleton cluster or until a stopping criterion is met.</p></li>
</ol>
</li>
</ul>
<p><img alt="img" src="../../../_images/img1.jpg" /></p>
</section>
<section id="dendrograms">
<h3>Dendrograms<a class="headerlink" href="#dendrograms" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>A <strong>dendrogram</strong> is a tree diagram used to illustrate the arrangement of clusters produced by hierarchical clustering.</p>
<ul class="simple">
<li><p><strong>Components</strong>:</p>
<ul>
<li><p><strong>Leaves</strong>: Represent individual data points.</p></li>
<li><p><strong>Branches</strong>: Represent clusters formed by merging data points or clusters.</p></li>
<li><p><strong>Height</strong>: Represents the distance or dissimilarity at which clusters are merged or split.</p></li>
</ul>
</li>
</ul>
<p><strong>Interpretation</strong>:</p>
<ul class="simple">
<li><p>By cutting the dendrogram at a particular height, we can obtain a specific number of clusters.</p></li>
<li><p>The height of the merge (vertical axis) corresponds to the distance between the clusters being merged.</p></li>
</ul>
<p><img alt="img2" src="../../../_images/img2.gif" /></p>
<p><strong>Agglomerative vs. Divisive Clustering</strong>:</p>
<ul class="simple">
<li><p><strong>Agglomerative Clustering</strong>:</p>
<ul>
<li><p>Starts with individual data points and merges them to form clusters.</p></li>
<li><p>Commonly used due to its simplicity and ease of implementation.</p></li>
<li><p>More computationally efficient for smaller datasets.</p></li>
</ul>
</li>
<li><p><strong>Divisive Clustering</strong>:</p>
<ul>
<li><p>Starts with the entire dataset and recursively splits it into smaller clusters.</p></li>
<li><p>Less commonly used due to higher computational complexity.</p></li>
<li><p>Can be more effective in certain situations where the global structure is more evident.</p></li>
</ul>
</li>
</ul>
<p><strong>Advantages of Hierarchical Clustering</strong>:</p>
<ul class="simple">
<li><p>Does not require specifying the number of clusters in advance.</p></li>
<li><p>Can capture complex relationships between data points.</p></li>
<li><p>The dendrogram provides a visual representation of data similarity.</p></li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul class="simple">
<li><p>Computationally intensive, especially for large datasets.</p></li>
<li><p>Once a merge or split is done, it cannot be undone (greedy approach).</p></li>
<li><p>Sensitive to noise and outliers.</p></li>
</ul>
</section>
</section>
<section id="distance-measures">
<h2>3. Distance Measures<a class="headerlink" href="#distance-measures" title="Link to this heading">#</a></h2>
<section id="euclidean-distance">
<h3>Euclidean Distance<a class="headerlink" href="#euclidean-distance" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>The <strong>Euclidean distance</strong> between two points <span class="math notranslate nohighlight">\( x = (x_1, x_2, \dots, x_n) \)</span> and <span class="math notranslate nohighlight">\( y = (y_1, y_2, \dots, y_n) \)</span> is:</p>
<div class="math notranslate nohighlight">
\[
d_{\text{Euclidean}}(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
\]</div>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Symmetry</strong>: <span class="math notranslate nohighlight">\( d(x, y) = d(y, x) \)</span></p></li>
<li><p><strong>Non-negativity</strong>: <span class="math notranslate nohighlight">\( d(x, y) \geq 0 \)</span></p></li>
<li><p><strong>Identity</strong>: <span class="math notranslate nohighlight">\( d(x, y) = 0 \)</span> if and only if <span class="math notranslate nohighlight">\( x = y \)</span></p></li>
<li><p><strong>Triangle Inequality</strong>: <span class="math notranslate nohighlight">\( d(x, z) \leq d(x, y) + d(y, z) \)</span></p></li>
</ul>
</section>
<section id="manhattan-distance">
<h3>Manhattan Distance<a class="headerlink" href="#manhattan-distance" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>The <strong>Manhattan distance</strong> (also known as Taxicab distance) between two points is:</p>
<div class="math notranslate nohighlight">
\[
d_{\text{Manhattan}}(x, y) = \sum_{i=1}^n |x_i - y_i|
\]</div>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p>Measures the distance between two points along axes at right angles.</p></li>
<li><p>Useful in grid-based layouts.</p></li>
</ul>
</section>
<section id="other-distance-metrics">
<h3>Other Distance Metrics<a class="headerlink" href="#other-distance-metrics" title="Link to this heading">#</a></h3>
<section id="minkowski-distance">
<h4>Minkowski Distance<a class="headerlink" href="#minkowski-distance" title="Link to this heading">#</a></h4>
<p><strong>Definition</strong>:</p>
<p>A generalization of both Euclidean and Manhattan distances:</p>
<div class="math notranslate nohighlight">
\[
d_{\text{Minkowski}}(x, y) = \left( \sum_{i=1}^n |x_i - y_i|^p \right)^{1/p}
\]</div>
<ul class="simple">
<li><p><strong>Special Cases</strong>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\( p = 1 \)</span>: Manhattan distance.</p></li>
<li><p><span class="math notranslate nohighlight">\( p = 2 \)</span>: Euclidean distance.</p></li>
</ul>
</li>
</ul>
</section>
<section id="cosine-similarity">
<h4>Cosine Similarity<a class="headerlink" href="#cosine-similarity" title="Link to this heading">#</a></h4>
<p><strong>Definition</strong>:</p>
<p>Measures the cosine of the angle between two non-zero vectors:</p>
<div class="math notranslate nohighlight">
\[
\text{Cosine Similarity}(x, y) = \frac{x \cdot y}{||x|| \, ||y||}
\]</div>
<ul class="simple">
<li><p><strong>Cosine Distance</strong>: <span class="math notranslate nohighlight">\( d_{\text{Cosine}}(x, y) = 1 - \text{Cosine Similarity}(x, y) \)</span></p></li>
</ul>
</section>
<section id="hamming-distance">
<h4>Hamming Distance<a class="headerlink" href="#hamming-distance" title="Link to this heading">#</a></h4>
<p><strong>Definition</strong>:</p>
<ul class="simple">
<li><p>Counts the number of positions at which the corresponding elements are different.</p></li>
<li><p>Applicable to strings or vectors of equal length.</p></li>
</ul>
<p><strong>Importance of Distance Measures</strong>:</p>
<ul class="simple">
<li><p>The choice of distance measure can significantly impact the clustering results.</p></li>
<li><p>Different distance measures capture different notions of similarity.</p></li>
</ul>
<p><strong>Scaling and Normalization</strong>:</p>
<ul>
<li><p><strong>Issue</strong>: Features with larger scales can dominate the distance calculations.</p></li>
<li><p><strong>Solution</strong>: Normalize or standardize the data.</p>
<ul>
<li><p><strong>Min-Max Scaling</strong>:</p>
<div class="math notranslate nohighlight">
\[
    x_{\text{scaled}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}
    \]</div>
</li>
<li><p><strong>Standardization (Z-score Normalization)</strong>:</p>
<div class="math notranslate nohighlight">
\[
    x_{\text{standardized}} = \frac{x - \mu}{\sigma}
    \]</div>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="id1">
<h3>Exercise<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Question</strong>: Calculate the Euclidean and Manhattan distances between <span class="math notranslate nohighlight">\( x = (3, 4) \)</span> and <span class="math notranslate nohighlight">\( y = (7, 1) \)</span>.</p></li>
</ul>
<p><strong>Solution</strong>:</p>
<p><strong>Euclidean Distance</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
d_{\text{Euclidean}}(x, y) &amp;= \sqrt{(3 - 7)^2 + (4 - 1)^2} \\
&amp;= \sqrt{(-4)^2 + (3)^2} \\
&amp;= \sqrt{16 + 9} \\
&amp;= \sqrt{25} \\
&amp;= 5 \\
\end{align*}
\end{split}\]</div>
<p><strong>Manhattan Distance</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
d_{\text{Manhattan}}(x, y) &amp;= |3 - 7| + |4 - 1| \\
&amp;= 4 + 3 \\
&amp;= 7 \\
\end{align*}
\end{split}\]</div>
<p><strong>Answer</strong>:</p>
<ul class="simple">
<li><p><strong>Euclidean Distance</strong>: 5</p></li>
<li><p><strong>Manhattan Distance</strong>: 7</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Define the points</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># Calculate Euclidean Distance</span>
<span class="n">euclidean_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Euclidean Distance: </span><span class="si">{</span><span class="n">euclidean_distance</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Calculate Manhattan Distance</span>
<span class="n">manhattan_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Manhattan Distance: </span><span class="si">{</span><span class="n">manhattan_distance</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Calculate Minkowski Distance (p=3 as an example)</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">minkowski_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span><span class="p">),</span> <span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Minkowski Distance (p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">): </span><span class="si">{</span><span class="n">minkowski_distance</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Calculate Cosine Similarity and Distance</span>
<span class="n">cosine_similarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="n">cosine_distance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">cosine_similarity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Cosine Distance: </span><span class="si">{</span><span class="n">cosine_distance</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Calculate Hamming Distance</span>
<span class="n">binary_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">binary_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">hamming_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">binary_x</span> <span class="o">!=</span> <span class="n">binary_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Hamming Distance: </span><span class="si">{</span><span class="n">hamming_distance</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Plotting the points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Point x (3, 4)&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Point y (7, 1)&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Plotting the Euclidean distance as a line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Euclidean Distance = </span><span class="si">{</span><span class="n">euclidean_distance</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Plotting the Manhattan distance (horizontal and vertical lines)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Manhattan Distance&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="c1"># Annotations for distances</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">euclidean_distance</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">((</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">manhattan_distance</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>

<span class="c1"># Set limits and labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distance Measures between Points x and y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X-axis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y-axis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Show the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Euclidean Distance: 5.00
Manhattan Distance: 7.00
Minkowski Distance (p=3): 4.50
Cosine Distance: 0.29
Hamming Distance: 1
</pre></div>
</div>
<img alt="../../../_images/e6f41c8d9ba51ae900e4aafd86ac08faf37091d83153e2b303d3e4621eafa29f.png" src="../../../_images/e6f41c8d9ba51ae900e4aafd86ac08faf37091d83153e2b303d3e4621eafa29f.png" />
</div>
</div>
</section>
</section>
<section id="linkage-criteria">
<h2>4. Linkage Criteria<a class="headerlink" href="#linkage-criteria" title="Link to this heading">#</a></h2>
<p>Linkage criteria determine how distances between clusters are computed based on the distances between data points.</p>
<section id="single-linkage">
<h3>Single Linkage<a class="headerlink" href="#single-linkage" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>The distance between two clusters <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> is the minimum distance between any pair of points <span class="math notranslate nohighlight">\(a \in A\)</span> and <span class="math notranslate nohighlight">\(b \in B\)</span>:</p>
<div class="math notranslate nohighlight">
\[
D_{\text{single}}(A, B) = \min_{a \in A, b \in B} d(a, b)
\]</div>
<p><strong>Characteristics</strong>:</p>
<ul class="simple">
<li><p>Can handle non-elliptical shapes.</p></li>
<li><p>May result in a “chaining” effect, forming long, elongated clusters.</p></li>
</ul>
</section>
<section id="complete-linkage">
<h3>Complete Linkage<a class="headerlink" href="#complete-linkage" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>The distance between two clusters <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> is the maximum distance between any pair of points <span class="math notranslate nohighlight">\(a \in A\)</span> and <span class="math notranslate nohighlight">\(b \in B\)</span>:</p>
<div class="math notranslate nohighlight">
\[
D_{\text{complete}}(A, B) = \max_{a \in A, b \in B} d(a, b)
\]</div>
<p><strong>Characteristics</strong>:</p>
<ul class="simple">
<li><p>Tends to produce compact clusters of approximately equal diameters.</p></li>
<li><p>More robust to outliers compared to single linkage.</p></li>
</ul>
</section>
<section id="average-linkage">
<h3>Average Linkage<a class="headerlink" href="#average-linkage" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>The distance between two clusters <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> is the average of all pairwise distances between points in <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>:</p>
<div class="math notranslate nohighlight">
\[
D_{\text{average}}(A, B) = \frac{1}{|A||B|} \sum_{a \in A} \sum_{b \in B} d(a, b)
\]</div>
<p><strong>Characteristics</strong>:</p>
<ul class="simple">
<li><p>Provides a compromise between single and complete linkage.</p></li>
<li><p>Considers all pairwise distances, offering a balanced approach.</p></li>
</ul>
</section>
<section id="ward-s-method">
<h3>Ward’s Method<a class="headerlink" href="#ward-s-method" title="Link to this heading">#</a></h3>
<p><strong>Definition</strong>:</p>
<p>Ward’s method minimizes the total within-cluster variance. At each step, the pair of clusters that leads to the minimum increase in total within-cluster variance after merging is chosen.</p>
<p><strong>Formula</strong>:</p>
<div class="math notranslate nohighlight">
\[
\Delta(A, B) = \frac{|A||B|}{|A| + |B|} || \bar{a} - \bar{b} ||^2
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(|A|, |B|\)</span>: Number of data points in clusters <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{a}, \bar{b}\)</span>: Centroids of clusters <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(|| \bar{a} - \bar{b} ||^2\)</span>: Squared Euclidean distance between centroids.</p></li>
</ul>
</section>
<section id="derivation-of-ward-s-method">
<h3>Derivation of Ward’s Method<a class="headerlink" href="#derivation-of-ward-s-method" title="Link to this heading">#</a></h3>
<p><strong>Objective</strong>:</p>
<p>Minimize the total within-cluster sum of squares (WCSS) after each merge.</p>
<p><strong>Steps</strong>:</p>
<ol class="arabic">
<li><p><strong>Compute Centroids</strong>:</p>
<div class="math notranslate nohighlight">
\[
   \bar{a} = \frac{1}{|A|} \sum_{x \in A} x, \quad \bar{b} = \frac{1}{|B|} \sum_{x \in B} x
   \]</div>
</li>
<li><p><strong>Calculate WCSS Before Merging</strong>:</p>
<div class="math notranslate nohighlight">
\[
   \text{WCSS}_{\text{before}} = \sum_{x \in A} || x - \bar{a} ||^2 + \sum_{x \in B} || x - \bar{b} ||^2
   \]</div>
</li>
<li><p><strong>Compute New Centroid After Merging</strong>:</p>
<div class="math notranslate nohighlight">
\[
   \bar{c} = \frac{|A| \bar{a} + |B| \bar{b}}{|A| + |B|}
   \]</div>
</li>
<li><p><strong>Calculate WCSS After Merging</strong>:</p>
<div class="math notranslate nohighlight">
\[
   \text{WCSS}_{\text{after}} = \sum_{x \in A \cup B} || x - \bar{c} ||^2
   \]</div>
</li>
<li><p><strong>Compute Increase in WCSS</strong>:</p>
<div class="math notranslate nohighlight">
\[
   \Delta(A, B) = \text{WCSS}_{\text{after}} - \text{WCSS}_{\text{before}}
   \]</div>
</li>
<li><p><strong>Derive the Formula</strong>:</p>
<ul>
<li><p>Through algebraic manipulation, arrive at:</p>
<div class="math notranslate nohighlight">
\[
     \Delta(A, B) = \frac{|A||B|}{|A| + |B|} || \bar{a} - \bar{b} ||^2
     \]</div>
</li>
</ul>
</li>
</ol>
<p><strong>Comparison of Linkage Criteria</strong>:</p>
<ul class="simple">
<li><p><strong>Single Linkage</strong>:</p>
<ul>
<li><p>Pros: Captures clusters with complex shapes.</p></li>
<li><p>Cons: Sensitive to noise and outliers; may create elongated clusters.</p></li>
</ul>
</li>
<li><p><strong>Complete Linkage</strong>:</p>
<ul>
<li><p>Pros: Tends to find compact clusters.</p></li>
<li><p>Cons: Can break large clusters due to outliers.</p></li>
</ul>
</li>
<li><p><strong>Average Linkage</strong>:</p>
<ul>
<li><p>Pros: Balances the effects of single and complete linkage.</p></li>
<li><p>Cons: Computationally more intensive due to averaging over all pairs.</p></li>
</ul>
</li>
<li><p><strong>Ward’s Method</strong>:</p>
<ul>
<li><p>Pros: Minimizes variance within clusters; often produces clusters of similar size.</p></li>
<li><p>Cons: Assumes spherical clusters; sensitive to outliers.</p></li>
</ul>
</li>
</ul>
<p><strong>Choosing a Linkage Criterion</strong>:</p>
<ul class="simple">
<li><p>Depends on the dataset and the specific requirements of the analysis.</p></li>
<li><p>Experimentation may be necessary to determine the most appropriate method.</p></li>
</ul>
</section>
<section id="id2">
<h3>Exercise<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p><strong>Dataset</strong>:</p>
<p>Clusters:</p>
<ul class="simple">
<li><p><strong>Cluster <span class="math notranslate nohighlight">\(A\)</span></strong>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(x_1 = (1, 2)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_2 = (2, 2)\)</span></p></li>
</ul>
</li>
<li><p><strong>Cluster <span class="math notranslate nohighlight">\(B\)</span></strong>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(x_3 = (5, 6)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_4 = (6, 5)\)</span></p></li>
</ul>
</li>
</ul>
<p>Compute the distance between clusters <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> using:</p>
<ol class="arabic simple">
<li><p>Single Linkage</p></li>
<li><p>Complete Linkage</p></li>
<li><p>Average Linkage</p></li>
<li><p>Ward’s Method</p></li>
</ol>
<p><strong>Solution</strong>:</p>
<p><strong>Step 1: Compute Pairwise Distances</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
d_{13} &amp;= \sqrt{(1 - 5)^2 + (2 - 6)^2} = \sqrt{16 + 16} = \sqrt{32} \approx 5.6569 \\
d_{14} &amp;= \sqrt{(1 - 6)^2 + (2 - 5)^2} = \sqrt{25 + 9} = \sqrt{34} \approx 5.8300 \\
d_{23} &amp;= \sqrt{(2 - 5)^2 + (2 - 6)^2} = \sqrt{9 + 16} = \sqrt{25} = 5.0000 \\
d_{24} &amp;= \sqrt{(2 - 6)^2 + (2 - 5)^2} = \sqrt{16 + 9} = \sqrt{25} = 5.0000 \\
\end{align*}
\end{split}\]</div>
<p><strong>1. Single Linkage</strong></p>
<div class="math notranslate nohighlight">
\[
D_{\text{single}}(A, B) = \min\{ d_{13}, d_{14}, d_{23}, d_{24} \} = \min\{ 5.6569, 5.8300, 5.0000, 5.0000 \} = 5.0000
\]</div>
<p><strong>2. Complete Linkage</strong></p>
<div class="math notranslate nohighlight">
\[
D_{\text{complete}}(A, B) = \max\{ d_{13}, d_{14}, d_{23}, d_{24} \} = \max\{ 5.6569, 5.8300, 5.0000, 5.0000 \} = 5.8300
\]</div>
<p><strong>3. Average Linkage</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
D_{\text{average}}(A, B) &amp;= \frac{1}{|A||B|} \sum_{a \in A} \sum_{b \in B} d(a, b) \\
&amp;= \frac{1}{4} (d_{13} + d_{14} + d_{23} + d_{24}) \\
&amp;= \frac{1}{4} (5.6569 + 5.8300 + 5.0000 + 5.0000) \\
&amp;= \frac{1}{4} (21.4869) \\
&amp;\approx 5.3717 \\
\end{align*}
\end{split}\]</div>
<p><strong>4. Ward’s Method</strong></p>
<p><strong>Compute Centroids</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\bar{a} &amp;= \frac{(1, 2) + (2, 2)}{2} = \left( \frac{3}{2}, 2 \right) \\
\bar{b} &amp;= \frac{(5, 6) + (6, 5)}{2} = \left( \frac{11}{2}, \frac{11}{2} \right) = (5.5, 5.5) \\
\end{align*}
\end{split}\]</div>
<p><strong>Compute Squared Distance Between Centroids</strong>:</p>
<div class="math notranslate nohighlight">
\[
|| \bar{a} - \bar{b} ||^2 = (1.5 - 5.5)^2 + (2 - 5.5)^2 = (-4)^2 + (-3.5)^2 = 16 + 12.25 = 28.25
\]</div>
<p><strong>Apply Ward’s Formula</strong>:</p>
<div class="math notranslate nohighlight">
\[
\Delta(A, B) = \frac{|A||B|}{|A| + |B|} || \bar{a} - \bar{b} ||^2 = \frac{2 \cdot 2}{4} \cdot 28.25 = 1 \cdot 28.25 = 28.25
\]</div>
<p>Compute Ward’s Distance:</p>
<div class="math notranslate nohighlight">
\[ 
D_{\text{Ward}}(A, B) = \sqrt{\Delta(A, B)} = \sqrt{28.25} \approx 5.3151
\]</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h3>
<p>The choice of linkage criterion significantly affects clustering results. The various methods suit different datasets and analysis goals.</p>
</section>
</section>
<section id="implementation-of-different-linkage-criterias-in-python">
<h2>Implementation of different Linkage criterias in Python<a class="headerlink" href="#implementation-of-different-linkage-criterias-in-python" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">linkage</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span>

<span class="c1"># Sample data points</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>  <span class="c1"># Point 1</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># Point 2</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>  <span class="c1"># Point 3</span>
    <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>  <span class="c1"># Point 4</span>
    <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>  <span class="c1"># Point 5</span>
    <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>  <span class="c1"># Point 6</span>
<span class="p">])</span>

<span class="c1"># Compute linkage matrices for different linkage methods</span>
<span class="n">Z_single</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;single&#39;</span><span class="p">)</span>
<span class="n">Z_complete</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;complete&#39;</span><span class="p">)</span>
<span class="n">Z_average</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">)</span>
<span class="n">Z_ward</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;ward&#39;</span><span class="p">)</span>

<span class="c1"># List of linkage matrices and their labels</span>
<span class="n">linkage_matrices</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;Single Linkage&#39;</span><span class="p">,</span> <span class="n">Z_single</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Complete Linkage&#39;</span><span class="p">,</span> <span class="n">Z_complete</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Average Linkage&#39;</span><span class="p">,</span> <span class="n">Z_average</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Ward</span><span class="se">\&#39;</span><span class="s1">s Method&#39;</span><span class="p">,</span> <span class="n">Z_ward</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1"># Plot dendrograms</span>
<span class="k">for</span> <span class="n">title</span><span class="p">,</span> <span class="n">Z</span> <span class="ow">in</span> <span class="n">linkage_matrices</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;P</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Dendrogram (</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Data Points&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>  <span class="c1"># Set y-axis limit to be between 0 and 15</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/31e2a65b0792634d60258f82a2e20c44f0183739e4694b2ba209f8cead1f3484.png" src="../../../_images/31e2a65b0792634d60258f82a2e20c44f0183739e4694b2ba209f8cead1f3484.png" />
<img alt="../../../_images/a16c242a89cb529e0e473b3fa704c82889db73978d9382754ce657e239910a81.png" src="../../../_images/a16c242a89cb529e0e473b3fa704c82889db73978d9382754ce657e239910a81.png" />
<img alt="../../../_images/345896b091077cd0faeed5a452741fc040bf0c43e09733e1609fca1b47395300.png" src="../../../_images/345896b091077cd0faeed5a452741fc040bf0c43e09733e1609fca1b47395300.png" />
<img alt="../../../_images/cfe3628c31da7cd3c74c02a9980e3b0ab6ffac369d0c2eec77a6a3e19bb6a670.png" src="../../../_images/cfe3628c31da7cd3c74c02a9980e3b0ab6ffac369d0c2eec77a6a3e19bb6a670.png" />
</div>
</div>
</section>
<section id="algorithm-steps">
<h2>5. Algorithm Steps<a class="headerlink" href="#algorithm-steps" title="Link to this heading">#</a></h2>
<section id="step-by-step-procedure">
<h3>Step-by-Step Procedure<a class="headerlink" href="#step-by-step-procedure" title="Link to this heading">#</a></h3>
<p><strong>Agglomerative Hierarchical Clustering Algorithm:</strong></p>
<ol class="arabic">
<li><p><strong>Compute the Initial Distance Matrix:</strong></p>
<ul class="simple">
<li><p>For all pairs of data points <span class="math notranslate nohighlight">\( x_i \)</span> and <span class="math notranslate nohighlight">\( x_j \)</span> in the dataset <span class="math notranslate nohighlight">\( X = \{ x_1, x_2, \dots, x_n \} \)</span>, compute the distance <span class="math notranslate nohighlight">\( d(x_i, x_j) \)</span> using a chosen distance metric (e.g., Euclidean distance).</p></li>
<li><p>This results in an <span class="math notranslate nohighlight">\( n \times n \)</span> symmetric distance matrix <span class="math notranslate nohighlight">\( D \)</span>.</p></li>
</ul>
</li>
<li><p><strong>Initialize Clusters:</strong></p>
<ul class="simple">
<li><p>Start with <span class="math notranslate nohighlight">\( n \)</span> singleton clusters, each containing one data point:
$<span class="math notranslate nohighlight">\(
C_1 = \{ x_1 \}, \quad C_2 = \{ x_2 \}, \dots, \quad C_n = \{ x_n \}
\)</span>$</p></li>
</ul>
</li>
<li><p><strong>Repeat Until Only One Cluster Remains:</strong></p>
<p>a. <strong>Find the Closest Pair of Clusters:</strong></p>
<ul class="simple">
<li><p>Identify the pair of clusters <span class="math notranslate nohighlight">\( (C_p, C_q) \)</span> with the smallest distance <span class="math notranslate nohighlight">\( D(C_p, C_q) \)</span> based on the chosen linkage criterion (e.g., single linkage, complete linkage).</p></li>
</ul>
<p>b. <strong>Merge the Closest Clusters:</strong></p>
<ul class="simple">
<li><p>Merge clusters <span class="math notranslate nohighlight">\( C_p \)</span> and <span class="math notranslate nohighlight">\( C_q \)</span> to form a new cluster <span class="math notranslate nohighlight">\( C_{pq} = C_p \cup C_q \)</span>.</p></li>
</ul>
<p>c. <strong>Update the Distance Matrix:</strong></p>
<ul class="simple">
<li><p>Remove the rows and columns corresponding to <span class="math notranslate nohighlight">\( C_p \)</span> and <span class="math notranslate nohighlight">\( C_q \)</span> from the distance matrix.</p></li>
<li><p>Compute distances between the new cluster <span class="math notranslate nohighlight">\( C_{pq} \)</span> and all other existing clusters using the linkage criterion.</p></li>
<li><p>Add a new row and column for <span class="math notranslate nohighlight">\( C_{pq} \)</span> in the distance matrix with the updated distances.</p></li>
</ul>
</li>
<li><p><strong>Construct the Dendrogram:</strong></p>
<ul class="simple">
<li><p>Record each merge operation and the distance at which clusters are merged.</p></li>
<li><p>Use this information to build the dendrogram, illustrating the hierarchical relationships.</p></li>
</ul>
</li>
</ol>
<p><strong>Why Updating the Distance Matrix is Necessary:</strong></p>
<ul class="simple">
<li><p>When clusters are merged, the distances between the new cluster and the remaining clusters need to be recalculated based on the linkage criterion.</p></li>
<li><p>This ensures that the algorithm accurately reflects the current state of the clustering process.</p></li>
</ul>
<p><strong>Linkage Criteria Impact on Distance Updates:</strong></p>
<ul class="simple">
<li><p><strong>Single Linkage:</strong></p>
<ul>
<li><p>Distance between the new cluster <span class="math notranslate nohighlight">\( C_{pq} \)</span> and another cluster <span class="math notranslate nohighlight">\( C_k \)</span> is:
$<span class="math notranslate nohighlight">\(
D_{\text{single}}(C_{pq}, C_k) = \min \left( D(C_p, C_k), \, D(C_q, C_k) \right)
\)</span>$</p></li>
</ul>
</li>
<li><p><strong>Complete Linkage:</strong></p>
<ul>
<li><p>Distance between the new cluster <span class="math notranslate nohighlight">\( C_{pq} \)</span> and another cluster <span class="math notranslate nohighlight">\( C_k \)</span> is:
$<span class="math notranslate nohighlight">\(
D_{\text{complete}}(C_{pq}, C_k) = \max \left( D(C_p, C_k), \, D(C_q, C_k) \right)
\)</span>$</p></li>
</ul>
</li>
<li><p><strong>Average Linkage:</strong></p>
<ul>
<li><p>Distance between the new cluster <span class="math notranslate nohighlight">\( C_{pq} \)</span> and another cluster <span class="math notranslate nohighlight">\( C_k \)</span> is:
$<span class="math notranslate nohighlight">\(
D_{\text{average}}(C_{pq}, C_k) = \frac{|C_p| \cdot D(C_p, C_k) + |C_q| \cdot D(C_q, C_k)}{|C_p| + |C_q|}
\)</span>$</p></li>
</ul>
</li>
<li><p><strong>Ward’s Method:</strong></p>
<ul>
<li><p>Update using:
$<span class="math notranslate nohighlight">\(
\Delta(C_{pq}, C_k) = \frac{(|C_p| + |C_k|) \cdot \Delta(C_p, C_k) + (|C_q| + |C_k|) \cdot \Delta(C_q, C_k) - |C_k| \cdot \Delta(C_p, C_q)}{|C_p| + |C_q| + |C_k|}
\)</span>$</p></li>
</ul>
</li>
</ul>
<p><strong>Optimization Strategies:</strong></p>
<ul class="simple">
<li><p><strong>Nearest Neighbor Chains:</strong></p>
<ul>
<li><p>Reduce the search space by maintaining a chain of nearest neighbors.</p></li>
</ul>
</li>
<li><p><strong>Heap Data Structures:</strong></p>
<ul>
<li><p>Use heaps to efficiently find the closest pair of clusters.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id3">
<h3>Exercise<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p><strong>Dataset:</strong></p>
<p>Consider the following data points in a one-dimensional space:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
x_1 &amp;= 1 \\
x_2 &amp;= 2 \\
x_3 &amp;= 5 \\
x_4 &amp;= 10 \\
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p><strong>Question: Perform agglomerative hierarchical clustering using all kinds of linkage criteria you have learned. At each step, show the distance matrix, the clusters being merged, and the updated distance matrix.</strong></p></li>
</ul>
</section>
<section id="complete-linkage-method">
<h3><strong>1. Complete Linkage Method</strong><a class="headerlink" href="#complete-linkage-method" title="Link to this heading">#</a></h3>
<p>In Complete Linkage, the distance between two clusters is defined as the <strong>maximum</strong> distance between any pair of points, one from each cluster.</p>
<section id="step-by-step-solution">
<h4><strong>Step-by-Step Solution</strong><a class="headerlink" href="#step-by-step-solution" title="Link to this heading">#</a></h4>
</section>
<section id="step-1-initial-distance-matrix">
<h4><strong>Step 1: Initial Distance Matrix</strong><a class="headerlink" href="#step-1-initial-distance-matrix" title="Link to this heading">#</a></h4>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cccc}
 &amp; x_1 &amp; x_2 &amp; x_3 &amp; x_4 \\
\hline
x_1 &amp; 0 &amp; 1 &amp; 4 &amp; 9 \\
x_2 &amp; 1 &amp; 0 &amp; 3 &amp; 8 \\
x_3 &amp; 4 &amp; 3 &amp; 0 &amp; 5 \\
x_4 &amp; 9 &amp; 8 &amp; 5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="step-2-initialize-clusters">
<h4><strong>Step 2: Initialize Clusters</strong><a class="headerlink" href="#step-2-initialize-clusters" title="Link to this heading">#</a></h4>
<div class="math notranslate nohighlight">
\[
C_1 = \{ x_1 \}, \quad C_2 = \{ x_2 \}, \quad C_3 = \{ x_3 \}, \quad C_4 = \{ x_4 \}
\]</div>
</section>
<section id="step-3-first-merge">
<h4><strong>Step 3: First Merge</strong><a class="headerlink" href="#step-3-first-merge" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Closest Pair:</strong> <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(C_2\)</span> with distance <span class="math notranslate nohighlight">\(D(C_1, C_2) = 1\)</span>.</p></li>
<li><p><strong>Merge to form:</strong> <span class="math notranslate nohighlight">\(C_{12} = \{ x_1, x_2 \}\)</span>.</p></li>
</ul>
</section>
<section id="step-4-update-the-distance-matrix-complete-linkage">
<h4><strong>Step 4: Update the Distance Matrix (Complete Linkage)</strong><a class="headerlink" href="#step-4-update-the-distance-matrix-complete-linkage" title="Link to this heading">#</a></h4>
<p>For Complete Linkage, the distance between clusters is the <strong>maximum</strong> distance between their elements.</p>
<ul class="simple">
<li><p><strong>Compute Distances:</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D(C_{12}, C_3) = \max(D(x_1, x_3), D(x_2, x_3)) = \max(4, 3) = 4\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D(C_{12}, C_4) = \max(D(x_1, x_4), D(x_2, x_4)) = \max(9, 8) = 9\)</span></p></li>
</ul>
</li>
<li><p><strong>Updated Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|ccc}
 &amp; C_{12} &amp; x_3 &amp; x_4 \\
\hline
C_{12} &amp; 0 &amp; 4 &amp; 9 \\
x_3 &amp; 4 &amp; 0 &amp; 5 \\
x_4 &amp; 9 &amp; 5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="step-5-second-merge">
<h4><strong>Step 5: Second Merge</strong><a class="headerlink" href="#step-5-second-merge" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Closest Pair:</strong> <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(x_3\)</span> with distance <span class="math notranslate nohighlight">\(D(C_{12}, x_3) = 4\)</span>.</p></li>
<li><p><strong>Merge to form:</strong> <span class="math notranslate nohighlight">\(C_{123} = \{ x_1, x_2, x_3 \}\)</span>.</p></li>
</ul>
</section>
<section id="step-6-update-the-distance-matrix-complete-linkage">
<h4><strong>Step 6: Update the Distance Matrix (Complete Linkage)</strong><a class="headerlink" href="#step-6-update-the-distance-matrix-complete-linkage" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Compute Distance:</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D(C_{123}, C_4) = \max(D(x_1, x_4), D(x_2, x_4), D(x_3, x_4)) = \max(9, 8, 5) = 9\)</span></p></li>
</ul>
</li>
<li><p><strong>Updated Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cc}
 &amp; C_{123} &amp; x_4 \\
\hline
C_{123} &amp; 0 &amp; 9 \\
x_4 &amp; 9 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="step-7-final-merge">
<h4><strong>Step 7: Final Merge</strong><a class="headerlink" href="#step-7-final-merge" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Merge:</strong> <span class="math notranslate nohighlight">\(C_{123}\)</span> and <span class="math notranslate nohighlight">\(x_4\)</span> to form <span class="math notranslate nohighlight">\(C_{1234} = \{ x_1, x_2, x_3, x_4 \}\)</span>.</p></li>
</ul>
</section>
</section>
<section id="single-linkage-method">
<h3><strong>2. Single Linkage Method</strong><a class="headerlink" href="#single-linkage-method" title="Link to this heading">#</a></h3>
<p>In Single Linkage, the distance between two clusters is defined as the <strong>minimum</strong> distance between any pair of points, one from each cluster.</p>
<section id="id4">
<h4><strong>Step-by-Step Solution</strong><a class="headerlink" href="#id4" title="Link to this heading">#</a></h4>
</section>
<section id="step-1-compute-the-initial-distance-matrix">
<h4><strong>Step 1: Compute the Initial Distance Matrix</strong><a class="headerlink" href="#step-1-compute-the-initial-distance-matrix" title="Link to this heading">#</a></h4>
<p>Since the data is one-dimensional, we use absolute differences:</p>
<div class="math notranslate nohighlight">
\[
D(x_i, x_j) = |x_i - x_j|
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cccc}
 &amp; x_1 &amp; x_2 &amp; x_3 &amp; x_4 \\
\hline
x_1 &amp; 0 &amp; 1 &amp; 4 &amp; 9 \\
x_2 &amp; 1 &amp; 0 &amp; 3 &amp; 8 \\
x_3 &amp; 4 &amp; 3 &amp; 0 &amp; 5 \\
x_4 &amp; 9 &amp; 8 &amp; 5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id5">
<h4><strong>Step 2: Initialize Clusters</strong><a class="headerlink" href="#id5" title="Link to this heading">#</a></h4>
<div class="math notranslate nohighlight">
\[
C_1 = \{ x_1 \}, \quad C_2 = \{ x_2 \}, \quad C_3 = \{ x_3 \}, \quad C_4 = \{ x_4 \}
\]</div>
</section>
<section id="id6">
<h4><strong>Step 3: First Merge</strong><a class="headerlink" href="#id6" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Find the Closest Pair:</strong></p>
<ul>
<li><p>The smallest non-zero distance is <span class="math notranslate nohighlight">\(D(x_1, x_2) = 1\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Merge:</strong></p>
<ul>
<li><p>Merge <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(C_2\)</span> to form <span class="math notranslate nohighlight">\(C_{12} = \{ x_1, x_2 \}\)</span>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="step-4-update-the-distance-matrix-single-linkage">
<h4><strong>Step 4: Update the Distance Matrix (Single Linkage)</strong><a class="headerlink" href="#step-4-update-the-distance-matrix-single-linkage" title="Link to this heading">#</a></h4>
<p>For Single Linkage, the distance between the new cluster <span class="math notranslate nohighlight">\(C_{12}\)</span> and another cluster is the <strong>minimum</strong> distance between any member of <span class="math notranslate nohighlight">\(C_{12}\)</span> and any member of the other cluster.</p>
<ul class="simple">
<li><p><strong>Compute Distances:</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D(C_{12}, C_3) = \min(D(x_1, x_3), D(x_2, x_3)) = \min(4, 3) = 3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D(C_{12}, C_4) = \min(D(x_1, x_4), D(x_2, x_4)) = \min(9, 8) = 8\)</span></p></li>
</ul>
</li>
<li><p><strong>Updated Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|ccc}
 &amp; C_{12} &amp; x_3 &amp; x_4 \\
\hline
C_{12} &amp; 0 &amp; 3 &amp; 8 \\
x_3 &amp; 3 &amp; 0 &amp; 5 \\
x_4 &amp; 8 &amp; 5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id7">
<h4><strong>Step 5: Second Merge</strong><a class="headerlink" href="#id7" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Find the Closest Pair:</strong></p>
<ul>
<li><p>The smallest distance is <span class="math notranslate nohighlight">\(D(C_{12}, C_3) = 3\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Merge:</strong></p>
<ul>
<li><p>Merge <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(C_3\)</span> to form <span class="math notranslate nohighlight">\(C_{123} = \{ x_1, x_2, x_3 \}\)</span>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="step-6-update-the-distance-matrix-single-linkage">
<h4><strong>Step 6: Update the Distance Matrix (Single Linkage)</strong><a class="headerlink" href="#step-6-update-the-distance-matrix-single-linkage" title="Link to this heading">#</a></h4>
<p>For Single Linkage, the distance between <span class="math notranslate nohighlight">\(C_{123}\)</span> and <span class="math notranslate nohighlight">\(x_4\)</span> is the <strong>minimum</strong> distance between any member of <span class="math notranslate nohighlight">\(C_{123}\)</span> and <span class="math notranslate nohighlight">\(x_4\)</span>.</p>
<ul class="simple">
<li><p><strong>Compute Distance:</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D(C_{123}, x_4) = \min(D(x_1, x_4), D(x_2, x_4), D(x_3, x_4)) = \min(9, 8, 5) = 5\)</span></p></li>
</ul>
</li>
<li><p><strong>Updated Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cc}
 &amp; C_{123} &amp; x_4 \\
\hline
C_{123} &amp; 0 &amp; 5 \\
x_4 &amp; 5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id8">
<h4><strong>Step 7: Final Merge</strong><a class="headerlink" href="#id8" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Merge:</strong> <span class="math notranslate nohighlight">\(C_{123}\)</span> and <span class="math notranslate nohighlight">\(x_4\)</span> to form <span class="math notranslate nohighlight">\(C_{1234} = \{ x_1, x_2, x_3, x_4 \}\)</span>.</p></li>
</ul>
</section>
</section>
<section id="average-linkage-method">
<h3><strong>3. Average Linkage Method</strong><a class="headerlink" href="#average-linkage-method" title="Link to this heading">#</a></h3>
<p>In Average Linkage, the distance between two clusters is defined as the <strong>average</strong> of all pairwise distances between points in the two clusters.</p>
<section id="id9">
<h4><strong>Step-by-Step Solution</strong><a class="headerlink" href="#id9" title="Link to this heading">#</a></h4>
</section>
<section id="id10">
<h4><strong>Step 1: Compute the Initial Distance Matrix</strong><a class="headerlink" href="#id10" title="Link to this heading">#</a></h4>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cccc}
 &amp; x_1 &amp; x_2 &amp; x_3 &amp; x_4 \\
\hline
x_1 &amp; 0 &amp; 1 &amp; 4 &amp; 9 \\
x_2 &amp; 1 &amp; 0 &amp; 3 &amp; 8 \\
x_3 &amp; 4 &amp; 3 &amp; 0 &amp; 5 \\
x_4 &amp; 9 &amp; 8 &amp; 5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id11">
<h4><strong>Step 2: Initialize Clusters</strong><a class="headerlink" href="#id11" title="Link to this heading">#</a></h4>
<div class="math notranslate nohighlight">
\[
C_1 = \{ x_1 \}, \quad C_2 = \{ x_2 \}, \quad C_3 = \{ x_3 \}, \quad C_4 = \{ x_4 \}
\]</div>
</section>
<section id="id12">
<h4><strong>Step 3: First Merge</strong><a class="headerlink" href="#id12" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Find the Closest Pair:</strong></p>
<ul>
<li><p>The smallest non-zero distance is <span class="math notranslate nohighlight">\(D(x_1, x_2) = 1\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Merge:</strong></p>
<ul>
<li><p>Merge <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(C_2\)</span> to form <span class="math notranslate nohighlight">\(C_{12} = \{ x_1, x_2 \}\)</span>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="step-4-update-the-distance-matrix-average-linkage">
<h4><strong>Step 4: Update the Distance Matrix (Average Linkage)</strong><a class="headerlink" href="#step-4-update-the-distance-matrix-average-linkage" title="Link to this heading">#</a></h4>
<p>For Average Linkage, the distance between the new cluster <span class="math notranslate nohighlight">\(C_{12}\)</span> and another cluster is the <strong>average</strong> of all pairwise distances between members of <span class="math notranslate nohighlight">\(C_{12}\)</span> and the other cluster.</p>
<ul class="simple">
<li><p><strong>Compute Distances:</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D(C_{12}, C_3) = \frac{D(x_1, x_3) + D(x_2, x_3)}{2} = \frac{4 + 3}{2} = 3.5\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D(C_{12}, C_4) = \frac{D(x_1, x_4) + D(x_2, x_4)}{2} = \frac{9 + 8}{2} = 8.5\)</span></p></li>
</ul>
</li>
<li><p><strong>Updated Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|ccc}
 &amp; C_{12} &amp; x_3 &amp; x_4 \\
\hline
C_{12} &amp; 0 &amp; 3.5 &amp; 8.5 \\
x_3 &amp; 3.5 &amp; 0 &amp; 5 \\
x_4 &amp; 8.5 &amp; 5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id13">
<h4><strong>Step 5: Second Merge</strong><a class="headerlink" href="#id13" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Find the Closest Pair:</strong></p>
<ul>
<li><p>The smallest distance is <span class="math notranslate nohighlight">\(D(C_{12}, C_3) = 3.5\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Merge:</strong></p>
<ul>
<li><p>Merge <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(C_3\)</span> to form <span class="math notranslate nohighlight">\(C_{123} = \{ x_1, x_2, x_3 \}\)</span>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="step-6-update-the-distance-matrix-average-linkage">
<h4><strong>Step 6: Update the Distance Matrix (Average Linkage)</strong><a class="headerlink" href="#step-6-update-the-distance-matrix-average-linkage" title="Link to this heading">#</a></h4>
<p>For Average Linkage, compute the average distance between all members of <span class="math notranslate nohighlight">\(C_{123}\)</span> and <span class="math notranslate nohighlight">\(x_4\)</span>.</p>
<ul class="simple">
<li><p><strong>Compute Distance:</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D(C_{123}, x_4) = \frac{D(x_1, x_4) + D(x_2, x_4) + D(x_3, x_4)}{3} = \frac{9 + 8 + 5}{3} = \frac{22}{3} \approx 7.333\)</span></p></li>
</ul>
</li>
<li><p><strong>Updated Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cc}
 &amp; C_{123} &amp; x_4 \\
\hline
C_{123} &amp; 0 &amp; 7.333 \\
x_4 &amp; 7.333 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id14">
<h4><strong>Step 7: Final Merge</strong><a class="headerlink" href="#id14" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Merge:</strong> <span class="math notranslate nohighlight">\(C_{123}\)</span> and <span class="math notranslate nohighlight">\(x_4\)</span> to form <span class="math notranslate nohighlight">\(C_{1234} = \{ x_1, x_2, x_3, x_4 \}\)</span>.</p></li>
</ul>
</section>
</section>
<section id="id15">
<h3><strong>4. Ward’s Method</strong><a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<p>Ward’s Method aims to <strong>minimize the total within-cluster variance</strong>. At each step, it merges the pair of clusters that leads to the smallest increase in the total within-cluster variance.</p>
<section id="id16">
<h4><strong>Step-by-Step Solution</strong><a class="headerlink" href="#id16" title="Link to this heading">#</a></h4>
</section>
<section id="understanding-ward-s-method-calculations">
<h4><strong>Understanding Ward’s Method Calculations</strong><a class="headerlink" href="#understanding-ward-s-method-calculations" title="Link to this heading">#</a></h4>
<p>For two clusters <span class="math notranslate nohighlight">\(C_p\)</span> and <span class="math notranslate nohighlight">\(C_q\)</span>, the Ward’s distance can be calculated as:</p>
<div class="math notranslate nohighlight">
\[
D_{\text{Ward}}(C_p, C_q) = \frac{|C_p| \times |C_q|}{|C_p| + |C_q|} \times (\mu_p - \mu_q)^2
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(|C_p|\)</span> and <span class="math notranslate nohighlight">\(|C_q|\)</span> are the sizes of the clusters.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_p\)</span> and <span class="math notranslate nohighlight">\(\mu_q\)</span> are the means of the clusters.</p></li>
</ul>
<p>This formula represents the increase in the total within-cluster variance when <span class="math notranslate nohighlight">\(C_p\)</span> and <span class="math notranslate nohighlight">\(C_q\)</span> are merged.</p>
</section>
<section id="step-1-compute-the-initial-ward-s-distance-matrix">
<h4><strong>Step 1: Compute the Initial Ward’s Distance Matrix</strong><a class="headerlink" href="#step-1-compute-the-initial-ward-s-distance-matrix" title="Link to this heading">#</a></h4>
<p>Given that all clusters are singletons initially, <span class="math notranslate nohighlight">\(|C_i| = 1\)</span> and <span class="math notranslate nohighlight">\(\mu_i = x_i\)</span>.</p>
<div class="math notranslate nohighlight">
\[
D_{\text{Ward}}(C_i, C_j) = \frac{1 \times 1}{1 + 1} \times (x_i - x_j)^2 = \frac{1}{2} \times (x_i - x_j)^2
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cccc}
 &amp; x_1 &amp; x_2 &amp; x_3 &amp; x_4 \\
\hline
x_1 &amp; 0 &amp; \frac{1}{2}(1-2)^2 = 0.5 &amp; \frac{1}{2}(1-5)^2 = 8 &amp; \frac{1}{2}(1-10)^2 = 40.5 \\
x_2 &amp; 0.5 &amp; 0 &amp; \frac{1}{2}(2-5)^2 = 4.5 &amp; \frac{1}{2}(2-10)^2 = 32 \\
x_3 &amp; 8 &amp; 4.5 &amp; 0 &amp; \frac{1}{2}(5-10)^2 = 12.5 \\
x_4 &amp; 40.5 &amp; 32 &amp; 12.5 &amp; 0 \\
\end{array}
\end{split}\]</div>
<p><strong>Initial Ward’s Distance Matrix:</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cccc}
 &amp; x_1 &amp; x_2 &amp; x_3 &amp; x_4 \\
\hline
x_1 &amp; 0 &amp; 0.5 &amp; 8 &amp; 40.5 \\
x_2 &amp; 0.5 &amp; 0 &amp; 4.5 &amp; 32 \\
x_3 &amp; 8 &amp; 4.5 &amp; 0 &amp; 12.5 \\
x_4 &amp; 40.5 &amp; 32 &amp; 12.5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id17">
<h4><strong>Step 2: Initialize Clusters</strong><a class="headerlink" href="#id17" title="Link to this heading">#</a></h4>
<div class="math notranslate nohighlight">
\[
C_1 = \{ x_1 \} \quad (\mu_1 = 1), \quad C_2 = \{ x_2 \} \quad (\mu_2 = 2), \quad C_3 = \{ x_3 \} \quad (\mu_3 = 5), \quad C_4 = \{ x_4 \} \quad (\mu_4 = 10)
\]</div>
</section>
<section id="id18">
<h4><strong>Step 3: First Merge</strong><a class="headerlink" href="#id18" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Find the Closest Pair:</strong></p>
<ul>
<li><p>The smallest non-zero Ward’s distance is <span class="math notranslate nohighlight">\(D_{\text{Ward}}(C_1, C_2) = 0.5\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Merge:</strong></p>
<ul>
<li><p>Merge <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(C_2\)</span> to form <span class="math notranslate nohighlight">\(C_{12} = \{ x_1, x_2 \}\)</span>.</p></li>
<li><p><strong>New Cluster Properties:</strong></p>
<ul>
<li><p>Size: <span class="math notranslate nohighlight">\(|C_{12}| = 2\)</span></p></li>
<li><p>Mean: <span class="math notranslate nohighlight">\(\mu_{12} = \frac{1 + 2}{2} = 1.5\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="step-4-update-the-distance-matrix-ward-s-method">
<h4><strong>Step 4: Update the Distance Matrix (Ward’s Method)</strong><a class="headerlink" href="#step-4-update-the-distance-matrix-ward-s-method" title="Link to this heading">#</a></h4>
<p>Now, we need to calculate the Ward’s distances between the new cluster <span class="math notranslate nohighlight">\(C_{12}\)</span> and the remaining clusters <span class="math notranslate nohighlight">\(C_3\)</span> and <span class="math notranslate nohighlight">\(C_4\)</span>.</p>
<p><strong>Formula for Ward’s Distance Between <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(C_k\)</span>:</strong></p>
<div class="math notranslate nohighlight">
\[
D_{\text{Ward}}(C_{12}, C_k) = \frac{|C_{12}| \times |C_k|}{|C_{12}| + |C_k|} \times (\mu_{12} - \mu_k)^2
\]</div>
<ul>
<li><p><strong>Compute Distances:</strong></p>
<ul>
<li><p><strong>Between <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(C_3\)</span>:</strong></p>
<div class="math notranslate nohighlight">
\[
    D_{\text{Ward}}(C_{12}, C_3) = \frac{2 \times 1}{2 + 1} \times (1.5 - 5)^2 = \frac{2}{3} \times (-3.5)^2 = \frac{2}{3} \times 12.25 = 8.1667
    \]</div>
</li>
<li><p><strong>Between <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(C_4\)</span>:</strong></p>
<div class="math notranslate nohighlight">
\[
    D_{\text{Ward}}(C_{12}, C_4) = \frac{2 \times 1}{2 + 1} \times (1.5 - 10)^2 = \frac{2}{3} \times (-8.5)^2 = \frac{2}{3} \times 72.25 = 48.1667
    \]</div>
</li>
</ul>
</li>
<li><p><strong>Updated Ward’s Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|ccc}
 &amp; C_{12} &amp; C_3 &amp; C_4 \\
\hline
C_{12} &amp; 0 &amp; 8.1667 &amp; 48.1667 \\
C_3 &amp; 8.1667 &amp; 0 &amp; 12.5 \\
C_4 &amp; 48.1667 &amp; 12.5 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id19">
<h4><strong>Step 5: Second Merge</strong><a class="headerlink" href="#id19" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Find the Closest Pair:</strong></p>
<ul>
<li><p>The smallest distance is <span class="math notranslate nohighlight">\(D_{\text{Ward}}(C_3, C_4) = 12.5\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Merge:</strong></p>
<ul>
<li><p>Merge <span class="math notranslate nohighlight">\(C_3\)</span> and <span class="math notranslate nohighlight">\(C_4\)</span> to form <span class="math notranslate nohighlight">\(C_{34} = \{ x_3, x_4 \}\)</span>.</p></li>
<li><p><strong>New Cluster Properties:</strong></p>
<ul>
<li><p>Size: <span class="math notranslate nohighlight">\(|C_{34}| = 2\)</span></p></li>
<li><p>Mean: <span class="math notranslate nohighlight">\(\mu_{34} = \frac{5 + 10}{2} = 7.5\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="step-6-update-the-distance-matrix-ward-s-method">
<h4><strong>Step 6: Update the Distance Matrix (Ward’s Method)</strong><a class="headerlink" href="#step-6-update-the-distance-matrix-ward-s-method" title="Link to this heading">#</a></h4>
<p>Now, calculate the Ward’s distance between <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(C_{34}\)</span>.</p>
<p><strong>Formula:</strong></p>
<div class="math notranslate nohighlight">
\[
D_{\text{Ward}}(C_{12}, C_{34}) = \frac{|C_{12}| \times |C_{34}|}{|C_{12}| + |C_{34}|} \times (\mu_{12} - \mu_{34})^2
\]</div>
<ul>
<li><p><strong>Compute Distance:</strong></p>
<div class="math notranslate nohighlight">
\[
  D_{\text{Ward}}(C_{12}, C_{34}) = \frac{2 \times 2}{2 + 2} \times (1.5 - 7.5)^2 = \frac{4}{4} \times (-6)^2 = 1 \times 36 = 36
  \]</div>
</li>
<li><p><strong>Updated Ward’s Distance Matrix:</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|cc}
 &amp; C_{12} &amp; C_{34} \\
\hline
C_{12} &amp; 0 &amp; 36 \\
C_{34} &amp; 36 &amp; 0 \\
\end{array}
\end{split}\]</div>
</section>
<section id="id20">
<h4><strong>Step 7: Final Merge</strong><a class="headerlink" href="#id20" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Merge:</strong> <span class="math notranslate nohighlight">\(C_{12}\)</span> and <span class="math notranslate nohighlight">\(C_{34}\)</span> to form <span class="math notranslate nohighlight">\(C_{1234} = \{ x_1, x_2, x_3, x_4 \}\)</span>.</p></li>
</ul>
</section>
</section>
<section id="summary-of-merges-for-each-method">
<h3><strong>Summary of Merges for Each Method</strong><a class="headerlink" href="#summary-of-merges-for-each-method" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Step</strong></p></th>
<th class="head"><p><strong>Complete Linkage</strong></p></th>
<th class="head"><p><strong>Single Linkage</strong></p></th>
<th class="head"><p><strong>Average Linkage</strong></p></th>
<th class="head"><p><strong>Ward’s Method</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_1\)</span> &amp; <span class="math notranslate nohighlight">\(C_2\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_1\)</span> &amp; <span class="math notranslate nohighlight">\(C_2\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_1\)</span> &amp; <span class="math notranslate nohighlight">\(C_2\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_1\)</span> &amp; <span class="math notranslate nohighlight">\(C_2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_{12}\)</span> &amp; <span class="math notranslate nohighlight">\(C_3\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_{12}\)</span> &amp; <span class="math notranslate nohighlight">\(C_3\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_{12}\)</span> &amp; <span class="math notranslate nohighlight">\(C_3\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_3\)</span> &amp; <span class="math notranslate nohighlight">\(C_4\)</span></p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_{123}\)</span> &amp; <span class="math notranslate nohighlight">\(C_4\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_{123}\)</span> &amp; <span class="math notranslate nohighlight">\(C_4\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_{123}\)</span> &amp; <span class="math notranslate nohighlight">\(C_4\)</span></p></td>
<td><p>Merge <span class="math notranslate nohighlight">\(C_{12}\)</span> &amp; <span class="math notranslate nohighlight">\(C_{34}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>Final Merge <span class="math notranslate nohighlight">\(C_{1234}\)</span></p></td>
<td><p>Final Merge <span class="math notranslate nohighlight">\(C_{1234}\)</span></p></td>
<td><p>Final Merge <span class="math notranslate nohighlight">\(C_{1234}\)</span></p></td>
<td><p>Final Merge <span class="math notranslate nohighlight">\(C_{1234}\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="agglomerative-single-linkage-clustering-implementation-in-python-step-by-step-explanation">
<h2>Agglomerative Single Linkage Clustering Implementation in Python (Step by step explanation)<a class="headerlink" href="#agglomerative-single-linkage-clustering-implementation-in-python-step-by-step-explanation" title="Link to this heading">#</a></h2>
<section id="importing-required-libraries">
<h3>1. Importing Required Libraries<a class="headerlink" href="#importing-required-libraries" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-1-load-the-data-into-a-dataframe">
<h3>2. Step 1: Load the Data into a DataFrame<a class="headerlink" href="#step-1-load-the-data-into-a-dataframe" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Alan&#39;</span><span class="p">,</span> <span class="s1">&#39;Lisa&#39;</span><span class="p">,</span> <span class="s1">&#39;Joe&#39;</span><span class="p">,</span> <span class="s1">&#39;Max&#39;</span><span class="p">,</span> <span class="s1">&#39;Cora&#39;</span><span class="p">],</span>
    <span class="s2">&quot;Social Media&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="s2">&quot;Gym&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Name&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initial Data:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initial Data:
      Social Media  Gym
Name                   
Alan             7    3
Lisa             5    2
Joe              5    3
Max              7    4
Cora             4    5
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>A dictionary data is created with the names of individuals and their engagement in two activities: “Social Media” and “Gym.”</p></li>
<li><p>The DataFrame is created from the dictionary and set_index() is used to make the “Name” column the index.</p></li>
</ul>
</section>
<section id="plot-initial-data-points">
<h3>3. Plot Initial Data Points<a class="headerlink" href="#plot-initial-data-points" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Media&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Gym&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Initial Data Points&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/a0c691022567ce228c91aea40b15b0c081f5fa6982ce34c61e864c85a6c05c47.png" src="../../../_images/a0c691022567ce228c91aea40b15b0c081f5fa6982ce34c61e864c85a6c05c47.png" />
</div>
</div>
<ul class="simple">
<li><p>A scatter plot is created to visualize the data, with ‘Social Media’ on the x-axis and ‘Gym’ on the y-axis.</p></li>
<li><p>iterrows() is used to loop through the rows of the DataFrame, and the text() function adds the labels (names) near each data point.</p></li>
</ul>
</section>
<section id="step-2-compute-the-linkage-matrix">
<h3>4. Step 2: Compute the Linkage Matrix<a class="headerlink" href="#step-2-compute-the-linkage-matrix" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;single&#39;</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>he linkage() function from scipy is used to perform hierarchical/agglomerative clustering.</p></li>
<li><p>The method=’single’ indicates single-linkage clustering, where the distance between two clusters is the minimum distance between their points.</p></li>
<li><p>The metric=’euclidean’ specifies Euclidean distance as the distance metric.</p></li>
</ul>
</section>
<section id="initialize-clusters">
<h3>5. Initialize Clusters<a class="headerlink" href="#initialize-clusters" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">current_clusters</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)}</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Each data point starts in its own cluster. A dictionary current_clusters is initialized, where the key is the cluster ID, and the value is a list of points in that cluster.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">idx_to_name</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>idx_to_name maps the DataFrame indices to the actual names of the individuals.</p></li>
</ul>
</section>
<section id="function-to-plot-clusters">
<h3>6. Function to Plot Clusters<a class="headerlink" href="#function-to-plot-clusters" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_clusters</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="s1">&#39;magenta&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cluster_indices</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
        <span class="n">cluster_points</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">cluster_indices</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cluster_points</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">],</span> <span class="n">cluster_points</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">],</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Cluster </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cluster_indices</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">idx_to_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Media&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Gym&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Clusters at Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This function plots the current clusters at each step of the agglomerative clustering process.</p></li>
<li><p>Different colors are used for each cluster.</p></li>
<li><p>Names are added next to each point.</p></li>
</ul>
</section>
<section id="function-to-plot-dendrogram">
<h3>7. Function to Plot Dendrogram<a class="headerlink" href="#function-to-plot-dendrogram" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">num_clusters</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">num_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">num_clusters</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-5</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Dendrogram at Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sample index&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Threshold&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This function plots the dendrogram (a tree-like diagram) showing how clusters are merged.</p></li>
<li><p>A threshold line is added based on the number of clusters at each step.</p></li>
</ul>
</section>
<section id="step-3-perform-agglomerative-clustering">
<h3>8. Step 3: Perform Agglomerative Clustering<a class="headerlink" href="#step-3-perform-agglomerative-clustering" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Starting Agglomerative Clustering:&quot;</span><span class="p">)</span>
<span class="n">total_steps</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Step </span><span class="si">{</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>
    <span class="c1"># Get clusters to merge</span>
    <span class="n">cluster1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">step</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">cluster2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">step</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">new_cluster_id</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">+</span> <span class="n">step</span>  <span class="c1"># New cluster ID</span>

    <span class="c1"># Get members of the clusters to be merged</span>
    <span class="n">members_cluster1</span> <span class="o">=</span> <span class="n">current_clusters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cluster1</span><span class="p">,</span> <span class="p">[</span><span class="n">cluster1</span><span class="p">])</span>
    <span class="n">members_cluster2</span> <span class="o">=</span> <span class="n">current_clusters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cluster2</span><span class="p">,</span> <span class="p">[</span><span class="n">cluster2</span><span class="p">])</span>

    <span class="c1"># Merge clusters</span>
    <span class="n">new_cluster_members</span> <span class="o">=</span> <span class="n">members_cluster1</span> <span class="o">+</span> <span class="n">members_cluster2</span>

    <span class="c1"># Update clusters</span>
    <span class="c1"># Remove old clusters</span>
    <span class="n">current_clusters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">cluster1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">current_clusters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">cluster2</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># Add new cluster</span>
    <span class="n">current_clusters</span><span class="p">[</span><span class="n">new_cluster_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_cluster_members</span>

    <span class="c1"># Display current clusters</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Clusters after merging:&quot;</span><span class="p">)</span>
    <span class="n">clusters_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">current_clusters</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters_list</span><span class="p">):</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx_to_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cluster</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Cluster </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Plot current clusters</span>
    <span class="n">plot_clusters</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">clusters_list</span><span class="p">,</span> <span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Plot dendrogram with current number of clusters</span>
    <span class="n">num_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters_list</span><span class="p">)</span>
    <span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">num_clusters</span><span class="p">,</span> <span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting Agglomerative Clustering:

--- Step 1 ---
Clusters after merging:
  Cluster 1: [&#39;Lisa&#39;]
  Cluster 2: [&#39;Joe&#39;]
  Cluster 3: [&#39;Cora&#39;]
  Cluster 4: [&#39;Alan&#39;, &#39;Max&#39;]
</pre></div>
</div>
<img alt="../../../_images/31c8781e51b0f2cf523f424b667695527e388f30a879862540379e73163fae59.png" src="../../../_images/31c8781e51b0f2cf523f424b667695527e388f30a879862540379e73163fae59.png" />
<img alt="../../../_images/5c48de5f84a40beb2eaefdda5786ef7b38b7a4212fd79c9588794fcc71e83102.png" src="../../../_images/5c48de5f84a40beb2eaefdda5786ef7b38b7a4212fd79c9588794fcc71e83102.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Step 2 ---
Clusters after merging:
  Cluster 1: [&#39;Cora&#39;]
  Cluster 2: [&#39;Alan&#39;, &#39;Max&#39;]
  Cluster 3: [&#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
<img alt="../../../_images/164519b0d7dc081008fdb4abc694e4dad7682f04813c07c3d679e1fcb4b6d61a.png" src="../../../_images/164519b0d7dc081008fdb4abc694e4dad7682f04813c07c3d679e1fcb4b6d61a.png" />
<img alt="../../../_images/26ced7c5a133f581ad905a5b1377c58fc9f60ea98daa0e4e1ef00e7b0d7e6cf2.png" src="../../../_images/26ced7c5a133f581ad905a5b1377c58fc9f60ea98daa0e4e1ef00e7b0d7e6cf2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Step 3 ---
Clusters after merging:
  Cluster 1: [&#39;Cora&#39;]
  Cluster 2: [&#39;Alan&#39;, &#39;Max&#39;, &#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
<img alt="../../../_images/d8bac74eca8b2aef1b979bd286f951631688355f599bfb0d1969e74508bdf013.png" src="../../../_images/d8bac74eca8b2aef1b979bd286f951631688355f599bfb0d1969e74508bdf013.png" />
<img alt="../../../_images/d4b51155d71877b4dc7a34b92224fe3991dfd73267e265712efdbcfe1e1cb63d.png" src="../../../_images/d4b51155d71877b4dc7a34b92224fe3991dfd73267e265712efdbcfe1e1cb63d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Step 4 ---
Clusters after merging:
  Cluster 1: [&#39;Cora&#39;, &#39;Alan&#39;, &#39;Max&#39;, &#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
<img alt="../../../_images/ba38ecbfc3483aa301a1aeb461e93d55ce86cd8a38010ab0e007e4c75a8033a9.png" src="../../../_images/ba38ecbfc3483aa301a1aeb461e93d55ce86cd8a38010ab0e007e4c75a8033a9.png" />
<img alt="../../../_images/a9e752f86b181dc90eb85a0e3bc30c2925477192eb1fe49dfdd193f8dd930d3d.png" src="../../../_images/a9e752f86b181dc90eb85a0e3bc30c2925477192eb1fe49dfdd193f8dd930d3d.png" />
</div>
</div>
<p>-The code implements step-by-step agglomerative clustering, merging two clusters at each iteration. Here’s a detailed breakdown:</p>
<ul class="simple">
<li><p>The process begins by determining the total number of steps, <code class="docutils literal notranslate"><span class="pre">total_steps</span></code>, which is based on the number of rows in the linkage matrix <code class="docutils literal notranslate"><span class="pre">Z</span></code>. The loop iterates through each step of the clustering process. In each step, two clusters (<code class="docutils literal notranslate"><span class="pre">cluster1</span></code> and <code class="docutils literal notranslate"><span class="pre">cluster2</span></code>) are identified for merging. These clusters are extracted from the linkage matrix <code class="docutils literal notranslate"><span class="pre">Z</span></code>. A new cluster ID is generated, representing the newly merged cluster. The code retrieves the members of both clusters to be merged. If the clusters contain more than one data point (from previous merges), the full list of points in those clusters is fetched. The members of the two clusters are combined into a new cluster (<code class="docutils literal notranslate"><span class="pre">new_cluster_members</span></code>). The old clusters (<code class="docutils literal notranslate"><span class="pre">cluster1</span></code> and <code class="docutils literal notranslate"><span class="pre">cluster2</span></code>) are removed from <code class="docutils literal notranslate"><span class="pre">current_clusters</span></code>, and the new merged cluster is added to the dictionary under <code class="docutils literal notranslate"><span class="pre">new_cluster_id</span></code>.</p></li>
<li><p>After each merge, the current state of the clusters is printed, showing which data points belong to each cluster. The <code class="docutils literal notranslate"><span class="pre">idx_to_name</span></code> dictionary maps the data point indices to their corresponding names. The function <code class="docutils literal notranslate"><span class="pre">plot_clusters</span></code> visualizes the current clusters after the merge. Each cluster is plotted with a different color on a 2D graph representing the “Social Media” and “Gym” features. Finally, the code calls <code class="docutils literal notranslate"><span class="pre">plot_dendrogram</span></code> to plot the hierarchical dendrogram at each step. The dendrogram illustrates how the clusters are merged over time. A threshold line is added to show the current number of clusters.</p></li>
</ul>
</section>
<section id="step-4-final-clusters">
<h3>9. Step 4: Final Clusters<a class="headerlink" href="#step-4-final-clusters" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step 4: Final Clusters</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Final Clusters:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters_list</span><span class="p">):</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx_to_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cluster</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Cluster </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final Clusters:
  Cluster 1: [&#39;Cora&#39;, &#39;Alan&#39;, &#39;Max&#39;, &#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The final clusters are printed after all merges are complete.</p></li>
</ul>
</section>
</section>
<section id="agglomerative-single-linkage-clustering-implementation-in-python-full-code">
<h2>Agglomerative Single Linkage Clustering Implementation in Python (Full code)<a class="headerlink" href="#agglomerative-single-linkage-clustering-implementation-in-python-full-code" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span>

<span class="c1"># Step 1: Load the data into a DataFrame</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Alan&#39;</span><span class="p">,</span> <span class="s1">&#39;Lisa&#39;</span><span class="p">,</span> <span class="s1">&#39;Joe&#39;</span><span class="p">,</span> <span class="s1">&#39;Max&#39;</span><span class="p">,</span> <span class="s1">&#39;Cora&#39;</span><span class="p">],</span>
    <span class="s2">&quot;Social Media&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="s2">&quot;Gym&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Name&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initial Data:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Plot the initial data points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Media&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Gym&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Initial Data Points&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Step 2: Compute the linkage matrix</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;single&#39;</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>

<span class="c1"># Initialize clusters: each data point is its own cluster</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">current_clusters</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)}</span>

<span class="c1"># Mapping from indices to names</span>
<span class="n">idx_to_name</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>

<span class="c1"># Function to plot clusters at each step</span>
<span class="k">def</span> <span class="nf">plot_clusters</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="s1">&#39;magenta&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cluster_indices</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
        <span class="n">cluster_points</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">cluster_indices</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cluster_points</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">],</span> <span class="n">cluster_points</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">],</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Cluster </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cluster_indices</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">idx_to_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Social Media&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Gym&#39;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Media&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Gym&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Clusters at Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Function to plot dendrogram with appropriate color threshold</span>
<span class="k">def</span> <span class="nf">plot_dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">num_clusters</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="c1"># Determine the color threshold to separate clusters</span>
    <span class="k">if</span> <span class="n">num_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># The threshold is the distance before the last merge at this step</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">num_clusters</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-5</span>  <span class="c1"># Small epsilon to include the last merge</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Dendrogram at Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sample index&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Threshold&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Step 3: Perform Agglomerative Clustering step by step</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Starting Agglomerative Clustering:&quot;</span><span class="p">)</span>
<span class="n">total_steps</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Step </span><span class="si">{</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>
    <span class="c1"># Get clusters to merge</span>
    <span class="n">cluster1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">step</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">cluster2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">step</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">new_cluster_id</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">+</span> <span class="n">step</span>  <span class="c1"># New cluster ID</span>

    <span class="c1"># Get members of the clusters to be merged</span>
    <span class="n">members_cluster1</span> <span class="o">=</span> <span class="n">current_clusters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cluster1</span><span class="p">,</span> <span class="p">[</span><span class="n">cluster1</span><span class="p">])</span>
    <span class="n">members_cluster2</span> <span class="o">=</span> <span class="n">current_clusters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cluster2</span><span class="p">,</span> <span class="p">[</span><span class="n">cluster2</span><span class="p">])</span>

    <span class="c1"># Merge clusters</span>
    <span class="n">new_cluster_members</span> <span class="o">=</span> <span class="n">members_cluster1</span> <span class="o">+</span> <span class="n">members_cluster2</span>

    <span class="c1"># Update clusters</span>
    <span class="c1"># Remove old clusters</span>
    <span class="n">current_clusters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">cluster1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">current_clusters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">cluster2</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># Add new cluster</span>
    <span class="n">current_clusters</span><span class="p">[</span><span class="n">new_cluster_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_cluster_members</span>

    <span class="c1"># Display current clusters</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Clusters after merging:&quot;</span><span class="p">)</span>
    <span class="n">clusters_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">current_clusters</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters_list</span><span class="p">):</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx_to_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cluster</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Cluster </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Plot current clusters</span>
    <span class="n">plot_clusters</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">clusters_list</span><span class="p">,</span> <span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Plot dendrogram with current number of clusters</span>
    <span class="n">num_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters_list</span><span class="p">)</span>
    <span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">num_clusters</span><span class="p">,</span> <span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Step 4: Final Clusters</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Final Clusters:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters_list</span><span class="p">):</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx_to_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cluster</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Cluster </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initial Data:
      Social Media  Gym
Name                   
Alan             7    3
Lisa             5    2
Joe              5    3
Max              7    4
Cora             4    5
</pre></div>
</div>
<img alt="../../../_images/a0c691022567ce228c91aea40b15b0c081f5fa6982ce34c61e864c85a6c05c47.png" src="../../../_images/a0c691022567ce228c91aea40b15b0c081f5fa6982ce34c61e864c85a6c05c47.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting Agglomerative Clustering:

--- Step 1 ---
Clusters after merging:
  Cluster 1: [&#39;Lisa&#39;]
  Cluster 2: [&#39;Joe&#39;]
  Cluster 3: [&#39;Cora&#39;]
  Cluster 4: [&#39;Alan&#39;, &#39;Max&#39;]
</pre></div>
</div>
<img alt="../../../_images/31c8781e51b0f2cf523f424b667695527e388f30a879862540379e73163fae59.png" src="../../../_images/31c8781e51b0f2cf523f424b667695527e388f30a879862540379e73163fae59.png" />
<img alt="../../../_images/5c48de5f84a40beb2eaefdda5786ef7b38b7a4212fd79c9588794fcc71e83102.png" src="../../../_images/5c48de5f84a40beb2eaefdda5786ef7b38b7a4212fd79c9588794fcc71e83102.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Step 2 ---
Clusters after merging:
  Cluster 1: [&#39;Cora&#39;]
  Cluster 2: [&#39;Alan&#39;, &#39;Max&#39;]
  Cluster 3: [&#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
<img alt="../../../_images/164519b0d7dc081008fdb4abc694e4dad7682f04813c07c3d679e1fcb4b6d61a.png" src="../../../_images/164519b0d7dc081008fdb4abc694e4dad7682f04813c07c3d679e1fcb4b6d61a.png" />
<img alt="../../../_images/26ced7c5a133f581ad905a5b1377c58fc9f60ea98daa0e4e1ef00e7b0d7e6cf2.png" src="../../../_images/26ced7c5a133f581ad905a5b1377c58fc9f60ea98daa0e4e1ef00e7b0d7e6cf2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Step 3 ---
Clusters after merging:
  Cluster 1: [&#39;Cora&#39;]
  Cluster 2: [&#39;Alan&#39;, &#39;Max&#39;, &#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
<img alt="../../../_images/d8bac74eca8b2aef1b979bd286f951631688355f599bfb0d1969e74508bdf013.png" src="../../../_images/d8bac74eca8b2aef1b979bd286f951631688355f599bfb0d1969e74508bdf013.png" />
<img alt="../../../_images/d4b51155d71877b4dc7a34b92224fe3991dfd73267e265712efdbcfe1e1cb63d.png" src="../../../_images/d4b51155d71877b4dc7a34b92224fe3991dfd73267e265712efdbcfe1e1cb63d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Step 4 ---
Clusters after merging:
  Cluster 1: [&#39;Cora&#39;, &#39;Alan&#39;, &#39;Max&#39;, &#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
<img alt="../../../_images/ba38ecbfc3483aa301a1aeb461e93d55ce86cd8a38010ab0e007e4c75a8033a9.png" src="../../../_images/ba38ecbfc3483aa301a1aeb461e93d55ce86cd8a38010ab0e007e4c75a8033a9.png" />
<img alt="../../../_images/a9e752f86b181dc90eb85a0e3bc30c2925477192eb1fe49dfdd193f8dd930d3d.png" src="../../../_images/a9e752f86b181dc90eb85a0e3bc30c2925477192eb1fe49dfdd193f8dd930d3d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final Clusters:
  Cluster 1: [&#39;Cora&#39;, &#39;Alan&#39;, &#39;Max&#39;, &#39;Lisa&#39;, &#39;Joe&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="refrences">
<h2>Refrences<a class="headerlink" href="#refrences" title="Link to this heading">#</a></h2>
<p><strong>1. <a class="reference external" href="https://primo.ai/index.php?title=Hierarchical_Clustering;_Agglomerative_%28HAC%29_%26_Divisive_%28HDC%29">Hierarchical Clustering; Agglomerative (HAC) &amp; Divisive (HDC)</a></strong></p>
<p><strong>2. <a class="reference external" href="https://datatab.net/tutorial/hierarchical-cluster-analysis">Hierarchical cluster analysis</a></strong></p>
<p><strong>3. <a class="reference external" href="https://datatab.net/statistics-calculator/cluster/hierarchical-cluster-analysis-calculator?example=hierarchical_cluster_analysis">Hierarchical cluster analysis calculator</a></strong></p>
<p><strong>4. <a class="reference external" href="https://youtu.be/VMyXc3SiEqs?si=3iAtz3mZxbS4zX8u">Hierarchical Clustering 3: single-link vs. complete-link</a></strong></p>
<p><strong>5. <a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering">Scikit-learn User Guide</a></strong></p>
<p><strong>6. <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html">SciPy Hierarchical Clustering and Dendrogram</a></strong></p>
<p><strong>7. <a class="reference external" href="https://www.geeksforgeeks.org/ml-types-of-linkages-in-clustering/">ML | Types of Linkages in Clustering</a></strong></p>
<p><strong>8. <a class="reference external" href="https://online.stat.psu.edu/stat555/node/86/">Example: Agglomerative Hierarchical Clustering</a></strong></p>
<p><strong>9. <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/cluster/plot_linkage_comparison.html">Comparing different hierarchical linkage methods on toy datasets</a></strong></p>
<p><strong>10. <a class="reference external" href="https://drive5.com/usearch/manual/linkage.html">Cluster linkage</a></strong></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./PR\StudentEffort\LinkageClustering1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../GloVe/GloVe1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">GloVe: Word Representation</p>
      </div>
    </a>
    <a class="right-next"
       href="../Word2Vec/Word2Vec.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Word2Vec</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-clustering">1. Basics of Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-of-clustering">Definition of Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-clustering">Types of Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-clutering-and-regression-and-classification"><strong>Difference between Clutering and Regression and Classification</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise  :</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-clustering">2. Hierarchical Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-of-hierarchical-clustering">Definition of Hierarchical Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-clustering-bottom-up">Agglomerative Clustering (Bottom-Up)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#divisive-clustering-top-down">Divisive Clustering (Top-Down)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dendrograms">Dendrograms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distance-measures">3. Distance Measures</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#euclidean-distance">Euclidean Distance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#manhattan-distance">Manhattan Distance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-distance-metrics">Other Distance Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#minkowski-distance">Minkowski Distance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-similarity">Cosine Similarity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hamming-distance">Hamming Distance</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Exercise</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linkage-criteria">4. Linkage Criteria</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-linkage">Single Linkage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-linkage">Complete Linkage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#average-linkage">Average Linkage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ward-s-method">Ward’s Method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#derivation-of-ward-s-method">Derivation of Ward’s Method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-of-different-linkage-criterias-in-python">Implementation of different Linkage criterias in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm-steps">5. Algorithm Steps</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-procedure">Step-by-Step Procedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Exercise</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-linkage-method"><strong>1. Complete Linkage Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-solution"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-initial-distance-matrix"><strong>Step 1: Initial Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-initialize-clusters"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-first-merge"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-complete-linkage"><strong>Step 4: Update the Distance Matrix (Complete Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-second-merge"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-complete-linkage"><strong>Step 6: Update the Distance Matrix (Complete Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-7-final-merge"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-linkage-method"><strong>2. Single Linkage Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-compute-the-initial-distance-matrix"><strong>Step 1: Compute the Initial Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-single-linkage"><strong>Step 4: Update the Distance Matrix (Single Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-single-linkage"><strong>Step 6: Update the Distance Matrix (Single Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#average-linkage-method"><strong>3. Average Linkage Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10"><strong>Step 1: Compute the Initial Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id11"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-average-linkage"><strong>Step 4: Update the Distance Matrix (Average Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id13"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-average-linkage"><strong>Step 6: Update the Distance Matrix (Average Linkage)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id14"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15"><strong>4. Ward’s Method</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id16"><strong>Step-by-Step Solution</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-ward-s-method-calculations"><strong>Understanding Ward’s Method Calculations</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-compute-the-initial-ward-s-distance-matrix"><strong>Step 1: Compute the Initial Ward’s Distance Matrix</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id17"><strong>Step 2: Initialize Clusters</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id18"><strong>Step 3: First Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-update-the-distance-matrix-ward-s-method"><strong>Step 4: Update the Distance Matrix (Ward’s Method)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id19"><strong>Step 5: Second Merge</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-update-the-distance-matrix-ward-s-method"><strong>Step 6: Update the Distance Matrix (Ward’s Method)</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id20"><strong>Step 7: Final Merge</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-merges-for-each-method"><strong>Summary of Merges for Each Method</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-single-linkage-clustering-implementation-in-python-step-by-step-explanation">Agglomerative Single Linkage Clustering Implementation in Python (Step by step explanation)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#importing-required-libraries">1. Importing Required Libraries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-load-the-data-into-a-dataframe">2. Step 1: Load the Data into a DataFrame</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-initial-data-points">3. Plot Initial Data Points</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-compute-the-linkage-matrix">4. Step 2: Compute the Linkage Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialize-clusters">5. Initialize Clusters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#function-to-plot-clusters">6. Function to Plot Clusters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#function-to-plot-dendrogram">7. Function to Plot Dendrogram</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-perform-agglomerative-clustering">8. Step 3: Perform Agglomerative Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-final-clusters">9. Step 4: Final Clusters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-single-linkage-clustering-implementation-in-python-full-code">Agglomerative Single Linkage Clustering Implementation in Python (Full code)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#refrences">Refrences</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr.Hadi Sadoghi Yazdi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024 Pattern Recognition Lab.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>