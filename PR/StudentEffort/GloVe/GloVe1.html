
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>GloVe: Word Representation &#8212; Dr.Hadi Sadoghi Yazdi</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'PR/StudentEffort/GloVe/GloVe1';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Linkage Clustering Algorithm" href="../LinkageClustering1/linkageclustering2.html" />
    <link rel="prev" title="Chernoff Faces in ESRI" href="../Chernoff/ChernoffEsri.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../pattern_recognition.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/Hadi_Sadoghi_Yazdi.png" class="logo__image only-light" alt="Dr.Hadi Sadoghi Yazdi - Home"/>
    <script>document.write(`<img src="../../../_static/Hadi_Sadoghi_Yazdi.png" class="logo__image only-dark" alt="Dr.Hadi Sadoghi Yazdi - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../pattern_recognition.html">
                    Pattern Recognition
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction of PR</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/PR_intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/DataSet.html">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/Model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/Cost.html">Cost_Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/LearningRule.html">Learning_Rule</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Visualization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Visualization/PR_intro_Visualization.html">Visualization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Clustering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/PR_intro_Clustering.html">Clustering Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/Clustering_1.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/FCM_1.html">k-means and fuzzy-c-means clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/FCM_Saghi_Project.html">Complementary of FCM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/LinkageClustering_1.html">Project Linkage clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/e_insensitive_linkage.html">Project <span class="math notranslate nohighlight">\( \epsilon \)</span> -insensitive Linkage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering/SOFM_Project.html">Project Title: Self-Organizing Feature Map (SOFM)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Regression</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Introduction_Regression.html">Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Regression_1.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/NonLinearRegression.html">Non-linear Regression: The starting point</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Linearization.html">Linearization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Kernel_for_Regression.html">Kernel method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/EvaluationModelSelection.html">Project : Evaluation and Model Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/Solution_for_Regression.html">Solution Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/TheoryRegression.html">Theoretical Aspects of Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Regression/ApplicationsPatternRecognition.html">Applications in Pattern Recognition</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Classification</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Classification/PR_intro_Classification.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/SVDD.html">Support Vector Data Description (SVDD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/SVM1.html">Support Vector Machine (SVM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/Fisherclassifier.html">Fihser Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/KernelFisherDiscriminantAnalysis.html">Kernel Fisher Discriminant Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/DecisionTree1.html">Project Induction in Decision Trees</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">BayesEstimation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/BayesEstimation.html">Bayes Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/KDE_1.html">kernel-based density estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/MeanShift.html">Mean Shift Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/ParametricDensityEstimation1.html">Parametric Density Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../BayesEstimation/GMM.html">Gaussian Mixture Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Student Effort</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Whyprojection1.html">What is Projection?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Star%20Coordinates/Star_Coordinates.html">Star Coordinates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Covariance_Fekri/Covariance_Poorya.html">Covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear-least-square-final/least-square.html">Linear Least Square Method</a></li>






<li class="toctree-l1"><a class="reference internal" href="../ECG/ecg.html">ECG: Measurement of heart rate and probability of heart attack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../correntropy/correntropy.html">Understanding Correntropy as a Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Normalization/Normalization_1.html">Data Normalization</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Chernoff/ChernoffEsri.html">Chernoff Faces in ESRI</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">GloVe: Word Representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LinkageClustering1/linkageclustering2.html">Linkage Clustering Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Word2Vec/Word2Vec.html">Word2Vec</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supplementary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/Supplementary1.html">Supplementary Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/EVD.html">Eigen Value Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/twin_svm.html">Twin SVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SupplementaryDocuments/Covariance1.html">Covariance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Contact</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../Contact_Me.html">Contact Me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../About_Me.html">About Me</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/h-sadoghi/dr-sadoghi.git" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/h-sadoghi/dr-sadoghi.git/issues/new?title=Issue%20on%20page%20%2FPR/StudentEffort/GloVe/GloVe1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/PR/StudentEffort/GloVe/GloVe1.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>GloVe: Word Representation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-glove">What is GloVe?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-we-need-glove">Why Do We Need GloVe?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-does-glove-work">How Does GloVe Work?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-co-occurrence-matrix">1: Building a Co-occurrence Matrix:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#capturing-relationships-between-words">2: Capturing Relationships Between Words:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-word-vectors">3: Learning Word Vectors:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-with-a-loss-function">4: Optimization with a Loss Function:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-vectors-as-final-output">5: Word Vectors as Final Output:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practice-with-code">Practice with code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#get-posts-from-telegram">Get posts from Telegram:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#import-required-libraries">1. Import Required Libraries:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-prepare-data-and-build-the-co-occurrence-matrix">2. Step 1: Prepare Data and Build the Co-occurrence Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#glove-loss-function">3. GloVe Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-glove-model">4. Training the GloVe Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#all-code-sections-in-one">All code sections in one:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-glove-is-effective">Why GloVe is Effective ?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-for-glove">Applications for GloVe:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-glove-and-word2vec">Difference Between GloVe and Word2Vec:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#refrences">Refrences:</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="glove-word-representation">
<h1>GloVe: Word Representation<a class="headerlink" href="#glove-word-representation" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p><strong>Author</strong> : Seyed Rasul Mortazavi Moghadam</p></li>
<li><p><strong>Contact</strong> : <a class="reference external" href="mailto:s&#46;rasul&#46;mortazavi&#37;&#52;&#48;gmail&#46;com">s<span>&#46;</span>rasul<span>&#46;</span>mortazavi<span>&#64;</span>gmail<span>&#46;</span>com</a></p></li>
</ul>
<p><img alt="GloVe" src="../../../_images/GloVe.jpg" /></p>
<section id="what-is-glove">
<h2>What is GloVe?<a class="headerlink" href="#what-is-glove" title="Link to this heading">#</a></h2>
<p><strong>GloVe</strong> (<strong>Glo</strong>bal <strong>Ve</strong>ctors for word representation), is a model for creating word embeddings that encodes both the <strong>meaning of words</strong> and their <strong>relationships</strong> with other words in the same vector space. The core idea behind GloVe is that the <strong>co-occurrence</strong> of words in a text can provide valuable information about their meanings. If two words frequently appear together (e.g., “king” and “queen”), then their meanings should be closely related. GloVe uses this co-occurrence information to generate vector representations of words that reflect these relationships.</p>
<p>GloVe encode the co-occurrence probability ratio between two words as vector differences. GloVe uses a weighted least squares objective
that minimizes the difference between the dot product of the vectors of two words and the logarithm of their number of co-occurrences:</p>
<p><strong>$<span class="math notranslate nohighlight">\(J=\sum_{i, j=1}^{V}f\left(𝑋_{i j}\right)(w^{T}_{i}\tilde{w}_{j} + b_{i} + \tilde{b}_{j} - \log{𝑋}_{ij})^{2}\)</span>$</strong></p>
<p>where <span class="math notranslate nohighlight">\(w_{i}\)</span> and <span class="math notranslate nohighlight">\(b_{i}\)</span> are the word vector and bias respectively of word <span class="math notranslate nohighlight">\({i}\)</span>, <span class="math notranslate nohighlight">\(w^{T}_{i}\)</span> and <span class="math notranslate nohighlight">\({b}_{j}\)</span> are the context word vector and bias respectively of word <span class="math notranslate nohighlight">\({j}\)</span>, <span class="math notranslate nohighlight">\({𝑋}_{ij}\)</span> is the number of times word <span class="math notranslate nohighlight">\({i}\)</span> occurs in the context of word <span class="math notranslate nohighlight">\({j}\)</span> (the values present in the Co-occurrence matrix), and <span class="math notranslate nohighlight">\(f\)</span> is a weighting function to reduce the impact of very frequent word pairs, such as stop words (e.g., “the,” “and”). It assigns lower weights to very frequent co-occurrences. The weighting function <span class="math notranslate nohighlight">\(f(x)\)</span> is designed to reduce the influence of very high <span class="math notranslate nohighlight">\(x\)</span> values, while still preserving important co-occurrence information.</p>
<p>The weighting function is typically defined as:
<strong>$<span class="math notranslate nohighlight">\(f(x) = \begin{cases} (\dfrac{x}{x_{max}})^\alpha &amp; \quad \text{\)</span>{x} &lt; x_{max}<span class="math notranslate nohighlight">\(}\\ 
1 &amp; \quad \text{otherwise}
\end{cases}\)</span>$</strong></p>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> is a tuning parameter and <span class="math notranslate nohighlight">\(x_{max}\)</span> is a threshold.</p>
<p><strong>Example:</strong>
For very frequent words like “the” or “on,” even if they co-occur often, their influence on the vector training is reduced.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @hidden_cell</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">xmax</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">3</span><span class="o">/</span><span class="mi">4</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">xmax</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">xmax</span><span class="p">)</span><span class="o">**</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;alpha = </span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">, xmax = </span><span class="si">{</span><span class="n">xmax</span><span class="si">}</span><span class="s1">&#39;</span> <span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># horizontal lines</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># vertical lines</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Weighting Function f(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/6da86199b9fa687e33a0cad895c8cbdf91d156b7949b9655548b88b628b25f96.png" src="../../../_images/6da86199b9fa687e33a0cad895c8cbdf91d156b7949b9655548b88b628b25f96.png" />
</div>
</div>
</section>
<section id="why-do-we-need-glove">
<h2>Why Do We Need GloVe?<a class="headerlink" href="#why-do-we-need-glove" title="Link to this heading">#</a></h2>
<p>Computers can’t directly understand words or text. They require numerical representations to process them. Early methods like <strong>Bag of Words</strong> and <strong>TF-IDF</strong> (Term Frequency-Inverse Document Frequency) were used to represent text as vectors, but they had significant limitations:</p>
<ul class="simple">
<li><p>They didn’t capture the meaning of words effectively.</p></li>
<li><p>Words with similar meanings were represented very differently.</p></li>
<li><p>There was no understanding of relationships between words, such as “cat” and “kitten.”</p></li>
</ul>
<p>To overcome these limitations, new methods like <strong>Word2Vec</strong> and <strong>GloVe</strong> were introduced to generate word embeddings, where each word is represented as a vector in a way that captures semantic relationships.</p>
</section>
<section id="how-does-glove-work">
<h2>How Does GloVe Work?<a class="headerlink" href="#how-does-glove-work" title="Link to this heading">#</a></h2>
<section id="building-a-co-occurrence-matrix">
<h3>1: Building a Co-occurrence Matrix:<a class="headerlink" href="#building-a-co-occurrence-matrix" title="Link to this heading">#</a></h3>
<p>GloVe starts by analyzing a large text corpus and creating a co-occurrence matrix. This matrix counts how frequently each word appears in the context of other words. The size of the context window (e.g., 5 words before and after) is defined.</p>
<p><strong>Example:</strong>
Consider the following sentences:</p>
<ul class="simple">
<li><p>“The cat sits on the mat.”</p></li>
<li><p>“The dog lies on the mat.”</p></li>
</ul>
<p>We build a co-occurrence matrix where each cell <em><span class="math notranslate nohighlight">\(𝑋_{i j}\)</span></em> represents how often word <em><span class="math notranslate nohighlight">\(j\)</span></em> appears in the context of word <em><span class="math notranslate nohighlight">\(i\)</span></em>.
<strong>co-occurrence matrix:</strong></p>
<center>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p></p></th>
<th class="head text-center"><p>the</p></th>
<th class="head text-center"><p>cat</p></th>
<th class="head text-center"><p>sits</p></th>
<th class="head text-center"><p>on</p></th>
<th class="head text-center"><p>mat</p></th>
<th class="head text-center"><p>dog</p></th>
<th class="head text-center"><p>lies</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><strong>the</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><strong>cat</strong></p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><strong>sits</strong></p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><strong>on</strong></p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><strong>mat</strong></p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><strong>dog</strong></p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>1</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><strong>lies</strong></p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p>0</p></td>
</tr>
</tbody>
</table>
</div>
</center>
<p>In this matrix, for instance, “cat” appears in the context of “the” 2 times, and “on” appears with “the” 2 times, and so on.</p>
<p>After the values are weighted based on the proximity or distance of the words from each other. This is an example representation; the actual weights would depend on how you define and calculate them based on your specific application (e.g., distance in terms of number of words, etc.).</p>
<p><strong>Weighted Co-occurrence Matrix:</strong></p>
<center>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>the</p></th>
<th class="head"><p>cat</p></th>
<th class="head"><p>sits</p></th>
<th class="head"><p>on</p></th>
<th class="head"><p>mat</p></th>
<th class="head"><p>dog</p></th>
<th class="head"><p>lies</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>the</strong></p></td>
<td><p>0</p></td>
<td><p>1.5</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>1.5</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p><strong>cat</strong></p></td>
<td><p>1.5</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p><strong>sits</strong></p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p><strong>on</strong></p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p><strong>mat</strong></p></td>
<td><p>1.5</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p><strong>dog</strong></p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p><strong>lies</strong></p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
</div>
</center></section>
<section id="capturing-relationships-between-words">
<h3>2: Capturing Relationships Between Words:<a class="headerlink" href="#capturing-relationships-between-words" title="Link to this heading">#</a></h3>
<p>The co-occurrence matrix captures how words are related. For example, “apple” and “fruit” might appear together frequently, so the matrix would reflect that connection. Conversely, “apple” and “car” might not appear together often, so their relationship is weaker.</p>
</section>
<section id="learning-word-vectors">
<h3>3: Learning Word Vectors:<a class="headerlink" href="#learning-word-vectors" title="Link to this heading">#</a></h3>
<p>GloVe uses the co-occurrence information to train word vectors. The idea is that two words that often appear together should have similar embeddings. The model tries to optimize the vectors so that the dot product of two word vectors reflects how often those words co-occur.</p>
</section>
<section id="optimization-with-a-loss-function">
<h3>4: Optimization with a Loss Function:<a class="headerlink" href="#optimization-with-a-loss-function" title="Link to this heading">#</a></h3>
<p>GloVe minimizes a loss function that measures how well the word embeddings predict the word co-occurrence information. The goal is to make sure that word vectors capture the relationships between words by preserving the global co-occurrence patterns. This process is done iteratively, adjusting the vectors after each iteration until it reaches a satisfactory solution.</p>
</section>
<section id="word-vectors-as-final-output">
<h3>5: Word Vectors as Final Output:<a class="headerlink" href="#word-vectors-as-final-output" title="Link to this heading">#</a></h3>
<p>After training, GloVe produces word embeddings: vectors that represent each word. These vectors can then be used for various NLP tasks, such as text classification, sentiment analysis, and machine translation.</p>
</section>
</section>
<section id="practice-with-code">
<h2>Practice with code<a class="headerlink" href="#practice-with-code" title="Link to this heading">#</a></h2>
<p>To feed the GloVe algorithm, here we use Telegram, we scrapes posts of a public channel using Telegram web preview.(in this example, we scrape Telegram’s own notification channel).</p>
<p><strong>Limitations</strong>:</p>
<ul class="simple">
<li><p><strong>Pagination and More Posts</strong>: This code only scrapes posts on the current page whitout pagination.</p></li>
<li><p><strong>Multimedia Posts</strong>: This code only extracts text content of the posts(not images, videos, …)</p></li>
<li><p><strong>Telegram Restrictions</strong>: If the channel is private or requires login, this method won’t work, since it only scrapes public content available on the web.</p></li>
</ul>
<section id="get-posts-from-telegram">
<h3>Get posts from Telegram:<a class="headerlink" href="#get-posts-from-telegram" title="Link to this heading">#</a></h3>
<ul>
<li><p><strong>Fetching the Web Page</strong>:</p>
<p>We first make a request to the web version of the Telegram channel to get the HTML content of the page.</p>
</li>
<li><p><strong>Parsing the Page</strong>:</p>
<p>The HTML content is then parsed using BeautifulSoup, allowing us to navigate through the HTML tree structure and locate the relevant elements (i.e., the posts).</p>
</li>
<li><p><strong>Extracting the Post Content</strong>:</p>
<p>All the posts are contained within &lt; div &gt; elements that share a specific class (tgme_widget_message_text). We extract all of these elements and loop through them to print the post content.</p>
</li>
</ul>
<p>Make sure that your internet connection is established and your IP address is not from Iran.
You can install required libraries using using the command below if you don’t have them already:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">requests</span> <span class="n">beautifulsoup4</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: requests in e:\mainhomepage\.m_homepage\lib\site-packages (2.32.3)
Requirement already satisfied: beautifulsoup4 in e:\mainhomepage\.m_homepage\lib\site-packages (4.12.3)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in e:\mainhomepage\.m_homepage\lib\site-packages (from requests) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in e:\mainhomepage\.m_homepage\lib\site-packages (from requests) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in e:\mainhomepage\.m_homepage\lib\site-packages (from requests) (1.26.19)
Requirement already satisfied: certifi&gt;=2017.4.17 in e:\mainhomepage\.m_homepage\lib\site-packages (from requests) (2024.6.2)
Requirement already satisfied: soupsieve&gt;1.2 in e:\mainhomepage\.m_homepage\lib\site-packages (from beautifulsoup4) (2.5)
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[notice] A new release of pip is available: 24.1.1 -&gt; 24.2
[notice] To update, run: E:\MainHomePage\.M_HomePage\Scripts\python.exe -m pip install --upgrade pip
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing Required Libraries:</span>

<span class="c1"># requests: This is a Python library used for sending HTTP requests. We use it to fetch the HTML content of the Telegram web preview.</span>
<span class="c1"># BeautifulSoup: from the bs4 module: This is used for parsing the HTML content and extracting the relevant information (in this case, the posts).</span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>


<span class="c1"># URL of the Public Channel:</span>
<span class="c1"># The URL points to the Telegram channel&#39;s web preview page, where posts are visible to users who don&#39;t have the app.</span>
<span class="c1"># URL of the Telegram channel preview page (https://t.me/s/CHANNLE_NAME)</span>
<span class="n">channel_url</span> <span class="o">=</span> <span class="s1">&#39;https://t.me/s/telegram&#39;</span>


<span class="c1"># a GET request to fetch the channel page</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">channel_url</span><span class="p">)</span>

<span class="c1"># check we get a successful response</span>
<span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>  

<span class="c1"># Parsing the HTML Content of the page with BeautifulSoup</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;lxml&#39;</span><span class="p">)</span>

<span class="c1"># Finding All the Posts</span>
<span class="c1"># We need to locate all the HTML elements that contain the post content.</span>
<span class="c1">#  On the Telegram web preview, post texts are typically contained within &lt;div&gt; elements that have the class tgme_widget_message_text.</span>
<span class="c1">#  We use soup.find_all() to find all these &lt;div&gt; elements.</span>
<span class="k">def</span> <span class="nf">get_posts</span><span class="p">(</span><span class="n">soup</span><span class="p">):</span>
    <span class="n">posts</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Find all the divs containing the posts</span>
    <span class="n">posts_text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;tgme_widget_message_text&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">post_text</span> <span class="ow">in</span> <span class="n">posts_text</span><span class="p">:</span>

        <span class="c1"># Check the post contains text</span>
        <span class="k">if</span> <span class="n">post_text</span><span class="p">:</span>
            <span class="n">post_content</span> <span class="o">=</span> <span class="n">post_text</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">separator</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">posts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post_content</span><span class="p">)</span>
    
    <span class="n">posts</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">posts</span>


<span class="n">posts</span> <span class="o">=</span> <span class="n">get_posts</span><span class="p">(</span><span class="n">soup</span><span class="p">)</span>

<span class="c1">#Corpus using in the next step</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Split each post by space into an array</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">post</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">posts</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">corpus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    
<span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">corpus</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TimeoutError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\connectionpool.py:404,</span> in <span class="ni">HTTPConnectionPool._make_request</span><span class="nt">(self, conn, method, url, timeout, chunked, **httplib_request_kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">403</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">404</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_validate_conn</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">405</span> <span class="k">except</span> <span class="p">(</span><span class="n">SocketTimeout</span><span class="p">,</span> <span class="n">BaseSSLError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">406</span>     <span class="c1"># Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\connectionpool.py:1060,</span> in <span class="ni">HTTPSConnectionPool._validate_conn</span><span class="nt">(self, conn)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="s2">&quot;sock&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>  <span class="c1"># AppEngine might not have  `.sock`</span>
<span class="ne">-&gt; </span><span class="mi">1060</span>     <span class="n">conn</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">conn</span><span class="o">.</span><span class="n">is_verified</span><span class="p">:</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\connection.py:419,</span> in <span class="ni">HTTPSConnection.connect</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">417</span>     <span class="n">context</span><span class="o">.</span><span class="n">load_default_certs</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">419</span> <span class="bp">self</span><span class="o">.</span><span class="n">sock</span> <span class="o">=</span> <span class="n">ssl_wrap_socket</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">420</span>     <span class="n">sock</span><span class="o">=</span><span class="n">conn</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">421</span>     <span class="n">keyfile</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">key_file</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">422</span>     <span class="n">certfile</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cert_file</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">423</span>     <span class="n">key_password</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">key_password</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">424</span>     <span class="n">ca_certs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ca_certs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">425</span>     <span class="n">ca_cert_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ca_cert_dir</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">426</span>     <span class="n">ca_cert_data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ca_cert_data</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">427</span>     <span class="n">server_hostname</span><span class="o">=</span><span class="n">server_hostname</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">428</span>     <span class="n">ssl_context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">429</span>     <span class="n">tls_in_tls</span><span class="o">=</span><span class="n">tls_in_tls</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">430</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">432</span> <span class="c1"># If we&#39;re using all defaults and the connection</span>
<span class="g g-Whitespace">    </span><span class="mi">433</span> <span class="c1"># is TLSv1 or TLSv1.1 we throw a DeprecationWarning</span>
<span class="g g-Whitespace">    </span><span class="mi">434</span> <span class="c1"># for the host.</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\util\ssl_.py:449,</span> in <span class="ni">ssl_wrap_socket</span><span class="nt">(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)</span>
<span class="g g-Whitespace">    </span><span class="mi">448</span> <span class="k">if</span> <span class="n">send_sni</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">449</span>     <span class="n">ssl_sock</span> <span class="o">=</span> <span class="n">_ssl_wrap_socket_impl</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">450</span>         <span class="n">sock</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">tls_in_tls</span><span class="p">,</span> <span class="n">server_hostname</span><span class="o">=</span><span class="n">server_hostname</span>
<span class="g g-Whitespace">    </span><span class="mi">451</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">452</span> <span class="k">else</span><span class="p">:</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\util\ssl_.py:493,</span> in <span class="ni">_ssl_wrap_socket_impl</span><span class="nt">(sock, ssl_context, tls_in_tls, server_hostname)</span>
<span class="g g-Whitespace">    </span><span class="mi">492</span> <span class="k">if</span> <span class="n">server_hostname</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">493</span>     <span class="k">return</span> <span class="n">ssl_context</span><span class="o">.</span><span class="n">wrap_socket</span><span class="p">(</span><span class="n">sock</span><span class="p">,</span> <span class="n">server_hostname</span><span class="o">=</span><span class="n">server_hostname</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">494</span> <span class="k">else</span><span class="p">:</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\ssl.py:455,</span> in <span class="ni">SSLContext.wrap_socket</span><span class="nt">(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)</span>
<span class="g g-Whitespace">    </span><span class="mi">449</span> <span class="k">def</span> <span class="nf">wrap_socket</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sock</span><span class="p">,</span> <span class="n">server_side</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">450</span>                 <span class="n">do_handshake_on_connect</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">451</span>                 <span class="n">suppress_ragged_eofs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">452</span>                 <span class="n">server_hostname</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">453</span>     <span class="c1"># SSLSocket class handles server_hostname encoding before it calls</span>
<span class="g g-Whitespace">    </span><span class="mi">454</span>     <span class="c1"># ctx._wrap_socket()</span>
<span class="ne">--&gt; </span><span class="mi">455</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sslsocket_class</span><span class="o">.</span><span class="n">_create</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">456</span>         <span class="n">sock</span><span class="o">=</span><span class="n">sock</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">457</span>         <span class="n">server_side</span><span class="o">=</span><span class="n">server_side</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">458</span>         <span class="n">do_handshake_on_connect</span><span class="o">=</span><span class="n">do_handshake_on_connect</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">459</span>         <span class="n">suppress_ragged_eofs</span><span class="o">=</span><span class="n">suppress_ragged_eofs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">460</span>         <span class="n">server_hostname</span><span class="o">=</span><span class="n">server_hostname</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">461</span>         <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">462</span>         <span class="n">session</span><span class="o">=</span><span class="n">session</span>
<span class="g g-Whitespace">    </span><span class="mi">463</span>     <span class="p">)</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\ssl.py:1042,</span> in <span class="ni">SSLSocket._create</span><span class="nt">(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)</span>
<span class="g g-Whitespace">   </span><span class="mi">1041</span>                 <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;do_handshake_on_connect should not be specified for non-blocking sockets&quot;</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1042</span>             <span class="bp">self</span><span class="o">.</span><span class="n">do_handshake</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1043</span> <span class="k">except</span><span class="p">:</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\ssl.py:1320,</span> in <span class="ni">SSLSocket.do_handshake</span><span class="nt">(self, block)</span>
<span class="g g-Whitespace">   </span><span class="mi">1319</span>         <span class="bp">self</span><span class="o">.</span><span class="n">settimeout</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1320</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_sslobj</span><span class="o">.</span><span class="n">do_handshake</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1321</span> <span class="k">finally</span><span class="p">:</span>

<span class="ne">TimeoutError</span>: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">ReadTimeoutError</span><span class="g g-Whitespace">                          </span>Traceback (most recent call last)
<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\requests\adapters.py:667,</span> in <span class="ni">HTTPAdapter.send</span><span class="nt">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="g g-Whitespace">    </span><span class="mi">666</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">667</span>     <span class="n">resp</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">668</span>         <span class="n">method</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">669</span>         <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">670</span>         <span class="n">body</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">body</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">671</span>         <span class="n">headers</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">672</span>         <span class="n">redirect</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">673</span>         <span class="n">assert_same_host</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">674</span>         <span class="n">preload_content</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">675</span>         <span class="n">decode_content</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">676</span>         <span class="n">retries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_retries</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">677</span>         <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">678</span>         <span class="n">chunked</span><span class="o">=</span><span class="n">chunked</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">679</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">681</span> <span class="k">except</span> <span class="p">(</span><span class="n">ProtocolError</span><span class="p">,</span> <span class="ne">OSError</span><span class="p">)</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\connectionpool.py:801,</span> in <span class="ni">HTTPConnectionPool.urlopen</span><span class="nt">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">799</span>     <span class="n">e</span> <span class="o">=</span> <span class="n">ProtocolError</span><span class="p">(</span><span class="s2">&quot;Connection aborted.&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">801</span> <span class="n">retries</span> <span class="o">=</span> <span class="n">retries</span><span class="o">.</span><span class="n">increment</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">802</span>     <span class="n">method</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">_pool</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">_stacktrace</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">803</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">804</span> <span class="n">retries</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\util\retry.py:552,</span> in <span class="ni">Retry.increment</span><span class="nt">(self, method, url, response, error, _pool, _stacktrace)</span>
<span class="g g-Whitespace">    </span><span class="mi">551</span> <span class="k">if</span> <span class="n">read</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_method_retryable</span><span class="p">(</span><span class="n">method</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">552</span>     <span class="k">raise</span> <span class="n">six</span><span class="o">.</span><span class="n">reraise</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">error</span><span class="p">),</span> <span class="n">error</span><span class="p">,</span> <span class="n">_stacktrace</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">553</span> <span class="k">elif</span> <span class="n">read</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\packages\six.py:770,</span> in <span class="ni">reraise</span><span class="nt">(tp, value, tb)</span>
<span class="g g-Whitespace">    </span><span class="mi">769</span>         <span class="k">raise</span> <span class="n">value</span><span class="o">.</span><span class="n">with_traceback</span><span class="p">(</span><span class="n">tb</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">770</span>     <span class="k">raise</span> <span class="n">value</span>
<span class="g g-Whitespace">    </span><span class="mi">771</span> <span class="k">finally</span><span class="p">:</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\connectionpool.py:715,</span> in <span class="ni">HTTPConnectionPool.urlopen</span><span class="nt">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">714</span> <span class="c1"># Make the request on the httplib connection object.</span>
<span class="ne">--&gt; </span><span class="mi">715</span> <span class="n">httplib_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_request</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">716</span>     <span class="n">conn</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">717</span>     <span class="n">method</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">718</span>     <span class="n">url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">719</span>     <span class="n">timeout</span><span class="o">=</span><span class="n">timeout_obj</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">720</span>     <span class="n">body</span><span class="o">=</span><span class="n">body</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">721</span>     <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">722</span>     <span class="n">chunked</span><span class="o">=</span><span class="n">chunked</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">723</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">725</span> <span class="c1"># If we&#39;re going to release the connection in ``finally:``, then</span>
<span class="g g-Whitespace">    </span><span class="mi">726</span> <span class="c1"># the response doesn&#39;t need to know about the connection. Otherwise</span>
<span class="g g-Whitespace">    </span><span class="mi">727</span> <span class="c1"># it will also try to release it and we&#39;ll have a double-release</span>
<span class="g g-Whitespace">    </span><span class="mi">728</span> <span class="c1"># mess.</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\connectionpool.py:407,</span> in <span class="ni">HTTPConnectionPool._make_request</span><span class="nt">(self, conn, method, url, timeout, chunked, **httplib_request_kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">405</span> <span class="k">except</span> <span class="p">(</span><span class="n">SocketTimeout</span><span class="p">,</span> <span class="n">BaseSSLError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">406</span>     <span class="c1"># Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.</span>
<span class="ne">--&gt; </span><span class="mi">407</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_raise_timeout</span><span class="p">(</span><span class="n">err</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">timeout_value</span><span class="o">=</span><span class="n">conn</span><span class="o">.</span><span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">408</span>     <span class="k">raise</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\urllib3\connectionpool.py:358,</span> in <span class="ni">HTTPConnectionPool._raise_timeout</span><span class="nt">(self, err, url, timeout_value)</span>
<span class="g g-Whitespace">    </span><span class="mi">357</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">err</span><span class="p">,</span> <span class="n">SocketTimeout</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">358</span>     <span class="k">raise</span> <span class="n">ReadTimeoutError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">359</span>         <span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="s2">&quot;Read timed out. (read timeout=</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">timeout_value</span>
<span class="g g-Whitespace">    </span><span class="mi">360</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">362</span> <span class="c1"># See the above comment about EAGAIN in Python 3. In Python 2 we have</span>
<span class="g g-Whitespace">    </span><span class="mi">363</span> <span class="c1"># to specifically catch it and throw the timeout error</span>

<span class="ne">ReadTimeoutError</span>: HTTPSConnectionPool(host=&#39;t.me&#39;, port=443): Read timed out. (read timeout=None)

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">ReadTimeout</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">line</span> <span class="mi">17</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="n">channel_url</span> <span class="o">=</span> <span class="s1">&#39;https://t.me/s/telegram&#39;</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="c1"># a GET request to fetch the channel page</span>
<span class="ne">---&gt; </span><span class="mi">17</span> <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">channel_url</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="c1"># check we get a successful response</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>  

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\requests\api.py:73,</span> in <span class="ni">get</span><span class="nt">(url, params, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span> <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span><span class="w">     </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sends a GET request.</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span><span class="sd"> </span>
<span class="g g-Whitespace">     </span><span class="mi">65</span><span class="sd">     :param url: URL for the new :class:`Request` object.</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">70</span><span class="sd">     :rtype: requests.Response</span>
<span class="g g-Whitespace">     </span><span class="mi">71</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">---&gt; </span><span class="mi">73</span>     <span class="k">return</span> <span class="n">request</span><span class="p">(</span><span class="s2">&quot;get&quot;</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\requests\api.py:59,</span> in <span class="ni">request</span><span class="nt">(method, url, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">55</span> <span class="c1"># By using the &#39;with&#39; statement we are sure the session is closed, thus we</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span> <span class="c1"># avoid leaving sockets open which can trigger a ResourceWarning in some</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span> <span class="c1"># cases, and look like a memory leak in others.</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span> <span class="k">with</span> <span class="n">sessions</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">59</span>     <span class="k">return</span> <span class="n">session</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\requests\sessions.py:589,</span> in <span class="ni">Session.request</span><span class="nt">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="g g-Whitespace">    </span><span class="mi">584</span> <span class="n">send_kwargs</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">    </span><span class="mi">585</span>     <span class="s2">&quot;timeout&quot;</span><span class="p">:</span> <span class="n">timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">586</span>     <span class="s2">&quot;allow_redirects&quot;</span><span class="p">:</span> <span class="n">allow_redirects</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">587</span> <span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">588</span> <span class="n">send_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">settings</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">589</span> <span class="n">resp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">prep</span><span class="p">,</span> <span class="o">**</span><span class="n">send_kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">591</span> <span class="k">return</span> <span class="n">resp</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\requests\sessions.py:703,</span> in <span class="ni">Session.send</span><span class="nt">(self, request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">700</span> <span class="n">start</span> <span class="o">=</span> <span class="n">preferred_clock</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">702</span> <span class="c1"># Send the request</span>
<span class="ne">--&gt; </span><span class="mi">703</span> <span class="n">r</span> <span class="o">=</span> <span class="n">adapter</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">request</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">705</span> <span class="c1"># Total elapsed time of the request (approximately)</span>
<span class="g g-Whitespace">    </span><span class="mi">706</span> <span class="n">elapsed</span> <span class="o">=</span> <span class="n">preferred_clock</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="nn">File E:\MainHomePage\.M_HomePage\Lib\site-packages\requests\adapters.py:713,</span> in <span class="ni">HTTPAdapter.send</span><span class="nt">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="g g-Whitespace">    </span><span class="mi">711</span>     <span class="k">raise</span> <span class="n">SSLError</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">712</span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">ReadTimeoutError</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">713</span>     <span class="k">raise</span> <span class="n">ReadTimeout</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">714</span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">_InvalidHeader</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">715</span>     <span class="k">raise</span> <span class="n">InvalidHeader</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">)</span>

<span class="ne">ReadTimeout</span>: HTTPSConnectionPool(host=&#39;t.me&#39;, port=443): Read timed out. (read timeout=None)
</pre></div>
</div>
</div>
</div>
<p>We have prepared the corpus up to this stage, now let’s go to the implementation of the glove algorithm.</p>
</section>
<section id="import-required-libraries">
<h3>1. Import Required Libraries:<a class="headerlink" href="#import-required-libraries" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>numpy</strong>: Used for numerical operations like matrix and vector calculations.</p></li>
<li><p><strong>collections.Counter</strong>: A specialized dictionary for counting occurrences of elements.</p></li>
<li><p><strong>collections.defaultdict</strong>: A dictionary that provides a default value for non-existing keys.</p></li>
<li><p><strong>tqdm</strong>: A library to show a progress bar during iteration (useful during training).</p></li>
<li><p><strong>itertools</strong>: Helps in working with iterators for efficient looping.</p></li>
<li><p><strong>matplotlib.pyplot</strong>: This library is used for plotting graphs in Python.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<p><strong>To install required libraries:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">numpy</span> <span class="n">collections</span> <span class="n">tqdm</span> <span class="n">itertools</span> <span class="n">matplotlib</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-1-prepare-data-and-build-the-co-occurrence-matrix">
<h3>2. Step 1: Prepare Data and Build the Co-occurrence Matrix<a class="headerlink" href="#step-1-prepare-data-and-build-the-co-occurrence-matrix" title="Link to this heading">#</a></h3>
<p>The first step in GloVe is to create a <strong>co-occurrence matrix</strong>, which captures how often words appear together within a given window size in the corpus.</p>
<ul class="simple">
<li><p><strong>Input</strong>: The corpus (list of tokenized sentences) and window_size (window_size=5 means we consider the 5 words before and after the target word as its context).</p></li>
<li><p><strong>Vocabulary</strong>: We extract all unique words from the corpus and assign each word a unique ID (word_to_id).</p></li>
<li><p><strong>Co-occurrence Matrix</strong>: For each word in a sentence, we count how often other words appear within its context window. The weight of the context word is inversely proportional to the distance from the target word.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step1: prepare data and build co-occurrence matrix</span>
<span class="k">def</span> <span class="nf">build_cooccurrence_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">corpus</span><span class="p">))</span>
    <span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
    <span class="n">id_to_word</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    
    <span class="n">cooccurrence_matrix</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="n">Counter</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
            <span class="n">word_id</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">window_size</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">),</span> <span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">context_word</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">context_word_id</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="n">context_word</span><span class="p">]</span>
                    <span class="n">cooccurrence_matrix</span><span class="p">[</span><span class="n">word_id</span><span class="p">][</span><span class="n">context_word_id</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">j</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>  <span class="c1"># weighted by distance</span>

    <span class="k">return</span> <span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="glove-loss-function">
<h3>3. GloVe Loss Function<a class="headerlink" href="#glove-loss-function" title="Link to this heading">#</a></h3>
<p>This function computes the loss for each word pair in the GloVe model.</p>
<ul class="simple">
<li><p><strong>wi</strong> and <strong>wj</strong>: The embedding vectors for the word and its context word.</p></li>
<li><p><strong>bi</strong> and <strong>bj</strong>: The biases for the word and its context word.</p></li>
<li><p><strong>Xij</strong>: The co-occurrence count between the word and context word.</p></li>
<li><p><strong>X_max</strong> and <strong>alpha</strong>: Hyperparameters used to weight the co-occurrence counts.</p></li>
</ul>
<p>The loss function minimizes the difference between the dot product of the word and context embeddings and the logarithm of the co-occurrence count, adjusted by a weighting function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GloVe loss function</span>
<span class="k">def</span> <span class="nf">glove_loss</span><span class="p">(</span><span class="n">wi</span><span class="p">,</span> <span class="n">wj</span><span class="p">,</span> <span class="n">bi</span><span class="p">,</span> <span class="n">bj</span><span class="p">,</span> <span class="n">Xij</span><span class="p">,</span> <span class="n">X_max</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="n">weighting</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xij</span> <span class="o">/</span> <span class="n">X_max</span><span class="p">)</span><span class="o">**</span><span class="n">alpha</span> <span class="k">if</span> <span class="n">Xij</span> <span class="o">&lt;</span> <span class="n">X_max</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-the-glove-model">
<h3>4. Training the GloVe Model<a class="headerlink" href="#training-the-glove-model" title="Link to this heading">#</a></h3>
<p>This function optimizes the word and context embeddings using gradient descent.</p>
<ul class="simple">
<li><p><strong>Parameters</strong>:</p>
<ul>
<li><p><strong>embedding_dim</strong>: The dimension of the word embeddings.</p></li>
<li><p><strong>iterations</strong>: The number of training epochs.</p></li>
<li><p><strong>learning_rate</strong>: The step size for the gradient descent.</p></li>
<li><p><strong>X_max</strong> and <strong>alpha</strong>: Control how much weight each co-occurrence count receives.</p></li>
</ul>
</li>
<li><p><strong>Initialization</strong>:</p>
<ul>
<li><p>Word and context embeddings (W, W_context) are initialized randomly.</p></li>
<li><p>Bias terms (biases, biases_context) are initialized to zeros.</p></li>
</ul>
</li>
<li><p><strong>Training Loop</strong>:</p>
<ul>
<li><p>For each epoch, the algorithm iterates over each word-context pair in the co-occurrence matrix.</p></li>
<li><p>Loss is calculated using the “glove_loss” function, and <strong>gradients</strong> are computed for each parameter.</p></li>
<li><p>Parameters (W, W_context, biases, and biases_context) are updated using gradient descent.</p></li>
<li><p>Progress is tracked using “tqdm”, and total loss is printed after each epoch.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Optimize parameters</span>
<span class="k">def</span> <span class="nf">train_glove</span><span class="p">(</span><span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">X_max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">):</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
    
    <span class="c1"># GloVe Model parameters</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">W_context</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">biases_context</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    
    <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Training</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">word_id</span><span class="p">,</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">cooccurrence_matrix</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">context_word_id</span><span class="p">,</span> <span class="n">Xij</span> <span class="ow">in</span> <span class="n">context</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># main word and context word</span>
                <span class="n">wi</span> <span class="o">=</span> <span class="n">W</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span>
                <span class="n">wj</span> <span class="o">=</span> <span class="n">W_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span>
                <span class="n">bi</span> <span class="o">=</span> <span class="n">biases</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span>
                <span class="n">bj</span> <span class="o">=</span> <span class="n">biases_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span>
                
                <span class="c1"># Calculate loss </span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">glove_loss</span><span class="p">(</span><span class="n">wi</span><span class="p">,</span> <span class="n">wj</span><span class="p">,</span> <span class="n">bi</span><span class="p">,</span> <span class="n">bj</span><span class="p">,</span> <span class="n">Xij</span><span class="p">,</span> <span class="n">X_max</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
                
                <span class="c1"># Gradient descent for each parameter</span>
                <span class="n">weighting</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xij</span> <span class="o">/</span> <span class="n">X_max</span><span class="p">)</span><span class="o">**</span><span class="n">alpha</span> <span class="k">if</span> <span class="n">Xij</span> <span class="o">&lt;</span> <span class="n">X_max</span> <span class="k">else</span> <span class="mi">1</span>
                <span class="n">grad_wi</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span> <span class="o">*</span> <span class="n">wj</span>
                <span class="n">grad_wj</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span> <span class="o">*</span> <span class="n">wi</span>
                <span class="n">grad_bi</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span>
                <span class="n">grad_bj</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span>
                
                <span class="c1"># Update parameters</span>
                <span class="n">W</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_wi</span>
                <span class="n">W_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_wj</span>
                <span class="n">biases</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_bi</span>
                <span class="n">biases_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_bj</span>

        <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">W_context</span><span class="p">,</span> <span class="n">loss_list</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Building the Co-occurrence Matrix</span>
<span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">build_cooccurrence_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">50</span>   <span class="c1"># Length of each word vector</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Number of epochs</span>

<span class="c1"># The GloVe model is trained for 100 iterations with a vector dimension of 50.</span>
<span class="n">W</span><span class="p">,</span> <span class="n">W_context</span><span class="p">,</span> <span class="n">loss_list</span> <span class="o">=</span> <span class="n">train_glove</span><span class="p">(</span><span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>



<span class="c1"># Plot Chart of loss by epoches</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> <span class="n">loss_list</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Vocabulary size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span> <span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss by epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">word</span> <span class="o">=</span> <span class="s1">&#39;Telegram&#39;</span>
<span class="n">word_id</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
<span class="n">word_vector</span> <span class="o">=</span> <span class="n">W</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span>

<span class="c1"># Show vector of an example word : &quot;telegram&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vector of &quot;</span><span class="s1">&#39;</span><span class="si">{word}</span><span class="s1">&#39;</span><span class="s2">&quot; word:</span><span class="se">\n</span><span class="si">{word_vector}</span><span class="s2">, word_id:</span><span class="si">{word_id}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Plot the word vector as a bar chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_vector</span><span class="p">)),</span> <span class="n">word_vector</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Word Vector for &quot;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Vector Component Index&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="all-code-sections-in-one">
<h2>All code sections in one:<a class="headerlink" href="#all-code-sections-in-one" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># URL of the Telegram channel preview page (https://t.me/s/CHANNLE_NAME)</span>
<span class="n">channel_url</span> <span class="o">=</span> <span class="s1">&#39;https://t.me/s/telegram&#39;</span>


<span class="c1"># a GET request to fetch the channel page</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">channel_url</span><span class="p">)</span>

<span class="c1"># check we get a successful response</span>
<span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>  

<span class="c1"># Parsing the HTML Content of the page with BeautifulSoup</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;lxml&#39;</span><span class="p">)</span>

<span class="c1"># Finding All the Posts</span>
<span class="k">def</span> <span class="nf">get_posts</span><span class="p">(</span><span class="n">soup</span><span class="p">):</span>
    <span class="n">posts</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Find all the divs containing the posts</span>
    <span class="n">posts_text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;tgme_widget_message_text&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">post_text</span> <span class="ow">in</span> <span class="n">posts_text</span><span class="p">:</span>

        <span class="c1"># Check the post contains text</span>
        <span class="k">if</span> <span class="n">post_text</span><span class="p">:</span>
            <span class="n">post_content</span> <span class="o">=</span> <span class="n">post_text</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">separator</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">posts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post_content</span><span class="p">)</span>
    
    <span class="n">posts</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">posts</span>


<span class="n">posts</span> <span class="o">=</span> <span class="n">get_posts</span><span class="p">(</span><span class="n">soup</span><span class="p">)</span>

<span class="c1">#Corpus using in the next step</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Split each post by space into an array</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">post</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">posts</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">corpus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    
<span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">corpus</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Step1: prepare data and build co-occurrence matrix</span>
<span class="k">def</span> <span class="nf">build_cooccurrence_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">corpus</span><span class="p">))</span>
    <span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
    <span class="n">id_to_word</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    
    <span class="n">cooccurrence_matrix</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="n">Counter</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
            <span class="n">word_id</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">window_size</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">),</span> <span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">context_word</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">context_word_id</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="n">context_word</span><span class="p">]</span>
                    <span class="n">cooccurrence_matrix</span><span class="p">[</span><span class="n">word_id</span><span class="p">][</span><span class="n">context_word_id</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">j</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>  <span class="c1"># weighted by distance</span>

    <span class="k">return</span> <span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span>


<span class="c1"># GloVe loss function</span>
<span class="k">def</span> <span class="nf">glove_loss</span><span class="p">(</span><span class="n">wi</span><span class="p">,</span> <span class="n">wj</span><span class="p">,</span> <span class="n">bi</span><span class="p">,</span> <span class="n">bj</span><span class="p">,</span> <span class="n">Xij</span><span class="p">,</span> <span class="n">X_max</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="n">weighting</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xij</span> <span class="o">/</span> <span class="n">X_max</span><span class="p">)</span><span class="o">**</span><span class="n">alpha</span> <span class="k">if</span> <span class="n">Xij</span> <span class="o">&lt;</span> <span class="n">X_max</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">loss</span>



<span class="c1"># Optimize parameters</span>
<span class="k">def</span> <span class="nf">train_glove</span><span class="p">(</span><span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">X_max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">):</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
    
    <span class="c1"># GloVe Model parameters</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">W_context</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">biases_context</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    
    <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Training</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">word_id</span><span class="p">,</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">cooccurrence_matrix</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">context_word_id</span><span class="p">,</span> <span class="n">Xij</span> <span class="ow">in</span> <span class="n">context</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># main word and context word</span>
                <span class="n">wi</span> <span class="o">=</span> <span class="n">W</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span>
                <span class="n">wj</span> <span class="o">=</span> <span class="n">W_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span>
                <span class="n">bi</span> <span class="o">=</span> <span class="n">biases</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span>
                <span class="n">bj</span> <span class="o">=</span> <span class="n">biases_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span>
                
                <span class="c1"># Calculate loss </span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">glove_loss</span><span class="p">(</span><span class="n">wi</span><span class="p">,</span> <span class="n">wj</span><span class="p">,</span> <span class="n">bi</span><span class="p">,</span> <span class="n">bj</span><span class="p">,</span> <span class="n">Xij</span><span class="p">,</span> <span class="n">X_max</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
                
                <span class="c1"># Gradient descent for each parameter</span>
                <span class="n">weighting</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xij</span> <span class="o">/</span> <span class="n">X_max</span><span class="p">)</span><span class="o">**</span><span class="n">alpha</span> <span class="k">if</span> <span class="n">Xij</span> <span class="o">&lt;</span> <span class="n">X_max</span> <span class="k">else</span> <span class="mi">1</span>
                <span class="n">grad_wi</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span> <span class="o">*</span> <span class="n">wj</span>
                <span class="n">grad_wj</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span> <span class="o">*</span> <span class="n">wi</span>
                <span class="n">grad_bi</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span>
                <span class="n">grad_bj</span> <span class="o">=</span> <span class="n">weighting</span> <span class="o">*</span> <span class="p">(</span><span class="n">wi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wj</span><span class="p">)</span> <span class="o">+</span> <span class="n">bi</span> <span class="o">+</span> <span class="n">bj</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Xij</span><span class="p">))</span>
                
                <span class="c1"># Update parameters</span>
                <span class="n">W</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_wi</span>
                <span class="n">W_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_wj</span>
                <span class="n">biases</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_bi</span>
                <span class="n">biases_context</span><span class="p">[</span><span class="n">context_word_id</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_bj</span>

        <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">W_context</span><span class="p">,</span> <span class="n">loss_list</span>


<span class="c1"># Building the Co-occurrence Matrix</span>
<span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">build_cooccurrence_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">50</span>   <span class="c1"># Length of each word vector</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Number of epochs</span>

<span class="c1"># The GloVe model is trained for 100 iterations with a vector dimension of 50.</span>
<span class="n">W</span><span class="p">,</span> <span class="n">W_context</span><span class="p">,</span> <span class="n">loss_list</span> <span class="o">=</span> <span class="n">train_glove</span><span class="p">(</span><span class="n">cooccurrence_matrix</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>



<span class="c1"># Plot Chart of loss by epoches</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> <span class="n">loss_list</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Vocabulary size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span> <span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss by epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">word</span> <span class="o">=</span> <span class="s1">&#39;Telegram&#39;</span>
<span class="n">word_id</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
<span class="n">word_vector</span> <span class="o">=</span> <span class="n">W</span><span class="p">[</span><span class="n">word_id</span><span class="p">]</span>

<span class="c1"># Show vector of an example word : &quot;telegram&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vector of </span><span class="se">\&quot;</span><span class="s2">&#39;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">&#39;</span><span class="se">\&quot;</span><span class="s2"> word :</span><span class="se">\n</span><span class="si">{</span><span class="n">word_vector</span><span class="si">}</span><span class="s2">, word_id:</span><span class="si">{</span><span class="n">word_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Plot the word vector as a bar chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_vector</span><span class="p">)),</span> <span class="n">word_vector</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Word Vector for &quot;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Vector Component Index&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;For&#39;, &#39;more&#39;, &#39;details&#39;, &#39;on&#39;, &#39;all&#39;, &#39;the&#39;, &#39;features&#39;, &#39;from&#39;, &#39;this&#39;, &#39;update,&#39;, &#39;check&#39;, &#39;out&#39;, &#39;our&#39;, &#39;latest&#39;, &#39;blog:&#39;, &#39;https://telegram.org/blog/gifts-verification-platform&#39;, &#39;October&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;RTMP&#39;, &#39;Streams&#39;, &#39;on&#39;, &#39;Android.&#39;, &#39;Telegram&#39;, &#39;for&#39;, &#39;Android&#39;, &#39;now&#39;, &#39;supports&#39;, &#39;livestreaming&#39;, &#39;with&#39;, &#39;RTMP&#39;, &#39;.&#39;, &#39;This&#39;, &#39;allows&#39;, &#39;users&#39;, &#39;to&#39;, &#39;generate&#39;, &#39;a&#39;, &#39;stream&#39;, &#39;key&#39;, &#39;and&#39;, &#39;connect&#39;, &#39;the&#39;, &#39;video&#39;, &#39;feed&#39;, &#39;to&#39;, &#39;popular&#39;, &#39;apps&#39;, &#39;.&#39;, &#39;October&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Improved&#39;, &#39;Reporting&#39;, &#39;Interface.&#39;, &#39;The&#39;, &#39;reporting&#39;, &#39;menu&#39;, &#39;has&#39;, &#39;been&#39;, &#39;expanded&#39;, &#39;with&#39;, &#39;detailed&#39;, &#39;options&#39;, &#39;for&#39;, &#39;each&#39;, &#39;category.&#39;, &#39;The&#39;, &#39;list&#39;, &#39;of&#39;, &#39;reporting&#39;, &#39;reasons&#39;, &#39;can&#39;, &#39;now&#39;, &#39;update&#39;, &#39;dynamically&#39;, &#39;–&#39;, &#39;further&#39;, &#39;improving&#39;, &#39;reports&#39;, &#39;for&#39;, &#39;moderators&#39;, &#39;and&#39;, &#39;helping&#39;, &#39;scale&#39;, &quot;Telegram&#39;s&quot;, &#39;AI&#39;, &#39;moderation&#39;, &#39;tools&#39;, &#39;.&#39;, &#39;October&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Verification&#39;, &#39;Platform.&#39;, &#39;Any&#39;, &#39;business,&#39;, &#39;app&#39;, &#39;or&#39;, &#39;website&#39;, &#39;can&#39;, &#39;now&#39;, &#39;use&#39;, &#39;Telegram&#39;, &#39;to&#39;, &#39;send&#39;, &#39;verification&#39;, &#39;codes&#39;, &#39;to&#39;, &#39;their&#39;, &#39;users&#39;, &#39;–&#39;, &#39;for&#39;, &#39;just&#39;, &#39;$0.01&#39;, &#39;per&#39;, &#39;message&#39;, &#39;.&#39;, &#39;Telegram&#39;, &#39;codes&#39;, &#39;are&#39;, &#39;also&#39;, &#39;faster,&#39;, &#39;more&#39;, &#39;secure&#39;, &#39;and&#39;, &#39;more&#39;, &#39;reliable&#39;, &#39;than&#39;, &#39;other&#39;, &#39;alternatives.&#39;, &#39;Interested&#39;, &#39;developers&#39;, &#39;can&#39;, &#39;learn&#39;, &#39;more&#39;, &#39;in&#39;, &#39;our&#39;, &#39;detailed&#39;, &#39;guide&#39;, &#39;.&#39;, &#39;October&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Gifts.&#39;, &#39;Users&#39;, &#39;can&#39;, &#39;now&#39;, &#39;send&#39;, &#39;gifts&#39;, &#39;to&#39;, &#39;each&#39;, &#39;other&#39;, &#39;–&#39;, &#39;celebrating&#39;, &#39;holidays&#39;, &#39;and&#39;, &#39;achievements&#39;, &#39;with&#39;, &#39;animated&#39;, &#39;artwork&#39;, &#39;and&#39;, &#39;custom&#39;, &#39;messages&#39;, &#39;.&#39;, &#39;Gifts&#39;, &#39;are&#39;, &#39;purchased&#39;, &#39;with&#39;, &#39;Telegram&#39;, &#39;Stars&#39;, &#39;–&#39;, &#39;recipients&#39;, &#39;can&#39;, &#39;choose&#39;, &#39;to&#39;, &#39;display&#39;, &#39;gifts&#39;, &#39;on&#39;, &#39;their&#39;, &#39;profile&#39;, &#39;or&#39;, &#39;convert&#39;, &#39;them&#39;, &#39;back&#39;, &#39;to&#39;, &#39;Stars&#39;, &#39;for&#39;, &#39;their&#39;, &#39;own&#39;, &#39;balance.&#39;, &#39;October&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Due&#39;, &#39;to&#39;, &#39;the&#39;, &#39;recent&#39;, &#39;events&#39;, &#39;in&#39;, &#39;the&#39;, &#39;Middle&#39;, &#39;East,&#39;, &#39;particularly&#39;, &#39;in&#39;, &#39;Israel,&#39;, &#39;Lebanon,&#39;, &#39;and&#39;, &#39;Iran,&#39;, &#39;Telegram&#39;, &#39;experienced&#39;, &#39;unprecedented&#39;, &#39;loads.&#39;, &#39;In&#39;, &#39;the&#39;, &#39;past&#39;, &#39;few&#39;, &#39;days,&#39;, &#39;some&#39;, &#39;users&#39;, &#39;may&#39;, &#39;have&#39;, &#39;faced&#39;, &#39;temporary&#39;, &#39;connection&#39;, &#39;issues&#39;, &#39;and&#39;, &#39;difficulties&#39;, &#39;accessing&#39;, &#39;media.&#39;, &#39;Thanks&#39;, &#39;to&#39;, &#39;our&#39;, &#39;technical&#39;, &quot;team&#39;s&quot;, &#39;efforts,&#39;, &#39;Telegram&#39;, &#39;remained&#39;, &#39;available&#39;, &#39;in&#39;, &#39;most&#39;, &#39;countries,&#39;, &#39;and&#39;, &#39;all&#39;, &#39;issues&#39;, &#39;are&#39;, &#39;now&#39;, &#39;fully&#39;, &#39;resolved.&#39;, &#39;We&#39;, &#39;apologize&#39;, &#39;for&#39;, &#39;any&#39;, &#39;inconvenience.&#39;]
[&#39;For&#39;, &#39;the&#39;, &#39;full&#39;, &#39;details&#39;, &#39;from&#39;, &#39;this&#39;, &quot;week&#39;s&quot;, &#39;update,&#39;, &#39;including&#39;, &#39;10&#39;, &#39;million&#39;, &#39;Premium&#39;, &#39;subscribers&#39;, &#39;and&#39;, &#39;dozens&#39;, &#39;of&#39;, &#39;bug&#39;, &#39;fixes,&#39;, &#39;check&#39;, &#39;out&#39;, &#39;our&#39;, &#39;latest&#39;, &#39;blog:&#39;, &#39;https://telegram.org/blog/star-giveaways-iv-in-browser&#39;, &#39;September&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Mini&#39;, &#39;App&#39;, &#39;Improvements.&#39;, &#39;Mini&#39;, &#39;apps&#39;, &#39;received&#39;, &#39;several&#39;, &#39;improvements,&#39;, &#39;making&#39;, &#39;them&#39;, &#39;smoother&#39;, &#39;and&#39;, &#39;more&#39;, &#39;responsive&#39;, &#39;.&#39;, &#39;Developers&#39;, &#39;can&#39;, &#39;now&#39;, &#39;display&#39;, &#39;two&#39;, &#39;buttons&#39;, &#39;at&#39;, &#39;a&#39;, &#39;time&#39;, &#39;in&#39;, &#39;their&#39;, &#39;app,&#39;, &#39;in&#39;, &#39;multiple&#39;, &#39;orientations&#39;, &#39;or&#39;, &#39;with&#39;, &#39;a&#39;, &#39;shimmer&#39;, &#39;effect&#39;, &#39;.&#39;, &#39;September&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Instant&#39;, &#39;View&#39;, &#39;for&#39;, &#39;Telegram&#39;, &#39;Browser.&#39;, &#39;Any&#39;, &#39;site&#39;, &#39;you&#39;, &#39;open&#39;, &#39;in&#39;, &#39;the&#39;, &#39;Telegram&#39;, &#39;Browser&#39;, &#39;can&#39;, &#39;be&#39;, &#39;converted&#39;, &#39;to&#39;, &#39;Instant&#39;, &#39;View&#39;, &#39;–&#39;, &#39;optimizing&#39;, &#39;articles&#39;, &#39;into&#39;, &#39;a&#39;, &#39;lightweight&#39;, &#39;layout&#39;, &#39;.&#39;, &#39;September&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Star&#39;, &#39;Giveaways.&#39;, &#39;Giveaways&#39;, &#39;in&#39;, &#39;groups&#39;, &#39;and&#39;, &#39;channels&#39;, &#39;now&#39;, &#39;support&#39;, &#39;Telegram&#39;, &#39;Stars&#39;, &#39;–&#39;, &#39;which&#39;, &#39;winners&#39;, &#39;can&#39;, &#39;spend&#39;, &#39;on&#39;, &#39;paid&#39;, &#39;media,&#39;, &#39;subscriptions&#39;, &#39;and&#39;, &#39;mini&#39;, &#39;apps.&#39;, &#39;September&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;📱&#39;, &#39;Telegram&#39;, &#39;abides&#39;, &#39;by&#39;, &#39;EU&#39;, &#39;laws,&#39;, &#39;including&#39;, &#39;the&#39;, &#39;Digital&#39;, &#39;Services&#39;, &#39;Act&#39;, &#39;—&#39;, &#39;its&#39;, &#39;moderation&#39;, &#39;is&#39;, &#39;within&#39;, &#39;industry&#39;, &#39;standards&#39;, &#39;and&#39;, &#39;constantly&#39;, &#39;improving.&#39;, &#39;🛩&#39;, &quot;Telegram&#39;s&quot;, &#39;CEO&#39;, &#39;Pavel&#39;, &#39;Durov&#39;, &#39;has&#39;, &#39;nothing&#39;, &#39;to&#39;, &#39;hide&#39;, &#39;and&#39;, &#39;travels&#39;, &#39;frequently&#39;, &#39;in&#39;, &#39;Europe.&#39;, &#39;🫤&#39;, &#39;It&#39;, &#39;is&#39;, &#39;absurd&#39;, &#39;to&#39;, &#39;claim&#39;, &#39;that&#39;, &#39;a&#39;, &#39;platform&#39;, &#39;or&#39;, &#39;its&#39;, &#39;owner&#39;, &#39;are&#39;, &#39;responsible&#39;, &#39;for&#39;, &#39;abuse&#39;, &#39;of&#39;, &#39;that&#39;, &#39;platform.&#39;, &#39;🌐&#39;, &#39;Almost&#39;, &#39;a&#39;, &#39;billion&#39;, &#39;users&#39;, &#39;globally&#39;, &#39;use&#39;, &#39;Telegram&#39;, &#39;as&#39;, &#39;means&#39;, &#39;of&#39;, &#39;communication&#39;, &#39;and&#39;, &#39;as&#39;, &#39;a&#39;, &#39;source&#39;, &#39;of&#39;, &#39;vital&#39;, &#39;information.&#39;, &#39;👍&#39;, &#39;We’re&#39;, &#39;awaiting&#39;, &#39;a&#39;, &#39;prompt&#39;, &#39;resolution&#39;, &#39;of&#39;, &#39;this&#39;, &#39;situation.&#39;, &#39;Telegram&#39;, &#39;is&#39;, &#39;with&#39;, &#39;you&#39;, &#39;all.&#39;]
[&#39;🎂&#39;, &#39;Telegram&#39;, &#39;celebrated&#39;, &#39;its&#39;, &#39;11th&#39;, &#39;birthday&#39;, &#39;this&#39;, &#39;week&#39;, &#39;–&#39;, &#39;and&#39;, &#39;has&#39;, &#39;had&#39;, &#39;17&#39;, &#39;major&#39;, &#39;updates&#39;, &#39;in&#39;, &#39;the&#39;, &#39;past&#39;, &#39;year.&#39;, &#39;For&#39;, &#39;the&#39;, &#39;full&#39;, &#39;details&#39;, &#39;(and&#39;, &#39;features)&#39;, &#39;from&#39;, &#39;this&#39;, &#39;celebration,&#39;, &#39;check&#39;, &#39;out&#39;, &#39;our&#39;, &#39;blog:&#39;, &#39;https://telegram.org/blog/superchannels-star-reactions-subscriptions&#39;, &#39;August&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Super&#39;, &#39;Channels.&#39;, &#39;Channel&#39;, &#39;owners&#39;, &#39;can&#39;, &#39;make&#39;, &#39;their&#39;, &#39;feed&#39;, &#39;look&#39;, &#39;more&#39;, &#39;like&#39;, &#39;a&#39;, &#39;group&#39;, &#39;–&#39;, &#39;allowing&#39;, &#39;admins&#39;, &#39;to&#39;, &#39;post&#39;, &#39;as&#39;, &#39;their&#39;, &#39;own&#39;, &#39;profiles&#39;, &#39;or&#39;, &#39;other&#39;, &#39;channels&#39;, &#39;.&#39;, &#39;August&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Paid&#39;, &#39;Media&#39;, &#39;for&#39;, &#39;Bots.&#39;, &#39;Bots&#39;, &#39;are&#39;, &#39;able&#39;, &#39;to&#39;, &#39;send&#39;, &#39;paid&#39;, &#39;media&#39;, &#39;–&#39;, &#39;to&#39;, &#39;support&#39;, &#39;their&#39;, &#39;services&#39;, &#39;and&#39;, &#39;automate&#39;, &#39;businesses&#39;, &#39;.&#39;, &#39;August&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Star&#39;, &#39;Subscriptions&#39;, &#39;.&#39;, &#39;Content&#39;, &#39;creators&#39;, &#39;can&#39;, &#39;make&#39;, &#39;special&#39;, &#39;invite&#39;, &#39;links&#39;, &#39;that&#39;, &#39;allow&#39;, &#39;users&#39;, &#39;to&#39;, &#39;join&#39;, &#39;a&#39;, &#39;channel&#39;, &#39;in&#39;, &#39;exchange&#39;, &#39;for&#39;, &#39;a&#39;, &#39;monthly&#39;, &#39;payment&#39;, &#39;in&#39;, &#39;Telegram&#39;, &#39;Stars&#39;, &#39;.&#39;, &#39;August&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Star&#39;, &#39;Reactions.&#39;, &#39;Users&#39;, &#39;can&#39;, &#39;directly&#39;, &#39;support&#39;, &#39;their&#39;, &#39;favorite&#39;, &#39;channels&#39;, &#39;and&#39;, &#39;content&#39;, &#39;creators&#39;, &#39;by&#39;, &#39;sending&#39;, &#39;them&#39;, &#39;Telegram&#39;, &#39;Stars&#39;, &#39;with&#39;, &#39;a&#39;, &#39;new&#39;, &#39;⭐️&#39;, &#39;Star&#39;, &#39;reaction&#39;, &#39;.&#39;, &#39;August&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;For&#39;, &#39;all&#39;, &#39;the&#39;, &#39;features&#39;, &#39;from&#39;, &#39;our&#39;, &#39;July&#39;, &#39;update&#39;, &#39;like&#39;, &#39;a&#39;, &#39;front&#39;, &#39;flash&#39;, &#39;for&#39;, &#39;video&#39;, &#39;messages&#39;, &#39;and&#39;, &#39;more&#39;, &#39;–&#39;, &#39;check&#39;, &#39;out&#39;, &#39;our&#39;, &#39;latest&#39;, &#39;blog:&#39;, &#39;https://telegram.org/blog/w3-browser-mini-app-store&#39;, &#39;July&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;5&#39;, &#39;•&#39;, &#39;6&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Story&#39;, &#39;Covers.&#39;, &#39;When&#39;, &#39;posting&#39;, &#39;a&#39;, &#39;video&#39;, &#39;story&#39;, &#39;to&#39;, &#39;your&#39;, &#39;profile,&#39;, &#39;you&#39;, &#39;can&#39;, &#39;choose&#39;, &#39;which&#39;, &#39;frame&#39;, &#39;to&#39;, &#39;use&#39;, &#39;as&#39;, &#39;its&#39;, &#39;cover&#39;, &#39;photo&#39;, &#39;.&#39;, &#39;July&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;5&#39;, &#39;•&#39;, &#39;6&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Weather&#39;, &#39;Widget&#39;, &#39;in&#39;, &#39;Stories.&#39;, &#39;You&#39;, &#39;can&#39;, &#39;share&#39;, &#39;the&#39;, &#39;weather&#39;, &#39;in&#39;, &#39;your&#39;, &#39;stories&#39;, &#39;–&#39;, &#39;adding&#39;, &#39;an&#39;, &#39;animated&#39;, &#39;widget&#39;, &#39;that&#39;, &#39;automatically&#39;, &#39;converts&#39;, &#39;temperature&#39;, &#39;between&#39;, &#39;C&#39;, &#39;and&#39;, &#39;F&#39;, &#39;and&#39;, &#39;shows&#39;, &#39;moon&#39;, &#39;phases&#39;, &#39;at&#39;, &#39;night.&#39;, &#39;July&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;5&#39;, &#39;•&#39;, &#39;6&#39;, &#39;•&#39;, &#39;More&#39;]
[&#39;Gifting&#39;, &#39;Telegram&#39;, &#39;Stars.&#39;, &#39;Telegram&#39;, &#39;Stars&#39;, &#39;can&#39;, &#39;be&#39;, &#39;purchased&#39;, &#39;for&#39;, &#39;your&#39;, &#39;contacts&#39;, &#39;–&#39;, &#39;giving&#39;, &#39;them&#39;, &#39;a&#39;, &#39;gift&#39;, &#39;to&#39;, &#39;spend&#39;, &#39;in&#39;, &#39;their&#39;, &#39;favorite&#39;, &#39;mini&#39;, &#39;apps&#39;, &#39;and&#39;, &#39;channels&#39;, &#39;.&#39;, &#39;July&#39;, &#39;Features&#39;, &#39;1&#39;, &#39;•&#39;, &#39;2&#39;, &#39;•&#39;, &#39;3&#39;, &#39;•&#39;, &#39;4&#39;, &#39;•&#39;, &#39;5&#39;, &#39;•&#39;, &#39;6&#39;, &#39;•&#39;, &#39;More&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: 100%|██████████| 378/378 [00:01&lt;00:00, 313.63it/s]
Epoch 2: 100%|██████████| 378/378 [00:01&lt;00:00, 314.15it/s]
Epoch 3: 100%|██████████| 378/378 [00:01&lt;00:00, 340.75it/s]
Epoch 4: 100%|██████████| 378/378 [00:01&lt;00:00, 301.86it/s]
Epoch 5: 100%|██████████| 378/378 [00:01&lt;00:00, 238.33it/s]
Epoch 6: 100%|██████████| 378/378 [00:01&lt;00:00, 328.61it/s]
Epoch 7: 100%|██████████| 378/378 [00:01&lt;00:00, 337.71it/s]
Epoch 8: 100%|██████████| 378/378 [00:01&lt;00:00, 340.22it/s]
Epoch 9: 100%|██████████| 378/378 [00:01&lt;00:00, 342.29it/s]
Epoch 10: 100%|██████████| 378/378 [00:01&lt;00:00, 338.31it/s]
Epoch 11: 100%|██████████| 378/378 [00:01&lt;00:00, 281.00it/s]
Epoch 12: 100%|██████████| 378/378 [00:01&lt;00:00, 344.16it/s]
Epoch 13: 100%|██████████| 378/378 [00:01&lt;00:00, 319.45it/s]
Epoch 14: 100%|██████████| 378/378 [00:01&lt;00:00, 341.06it/s]
Epoch 15: 100%|██████████| 378/378 [00:01&lt;00:00, 335.02it/s]
Epoch 16: 100%|██████████| 378/378 [00:01&lt;00:00, 285.25it/s]
Epoch 17: 100%|██████████| 378/378 [00:01&lt;00:00, 334.13it/s]
Epoch 18: 100%|██████████| 378/378 [00:01&lt;00:00, 322.73it/s]
Epoch 19: 100%|██████████| 378/378 [00:01&lt;00:00, 330.33it/s]
Epoch 20: 100%|██████████| 378/378 [00:01&lt;00:00, 315.72it/s]
Epoch 21: 100%|██████████| 378/378 [00:01&lt;00:00, 308.76it/s]
Epoch 22: 100%|██████████| 378/378 [00:01&lt;00:00, 224.20it/s]
Epoch 23: 100%|██████████| 378/378 [00:01&lt;00:00, 189.12it/s]
Epoch 24: 100%|██████████| 378/378 [00:02&lt;00:00, 129.84it/s]
Epoch 25: 100%|██████████| 378/378 [00:02&lt;00:00, 157.20it/s]
Epoch 26: 100%|██████████| 378/378 [00:02&lt;00:00, 150.99it/s]
Epoch 27: 100%|██████████| 378/378 [00:01&lt;00:00, 269.54it/s]
Epoch 28: 100%|██████████| 378/378 [00:01&lt;00:00, 270.94it/s]
Epoch 29: 100%|██████████| 378/378 [00:01&lt;00:00, 291.17it/s]
Epoch 30: 100%|██████████| 378/378 [00:01&lt;00:00, 318.65it/s]
Epoch 31: 100%|██████████| 378/378 [00:01&lt;00:00, 315.19it/s]
Epoch 32: 100%|██████████| 378/378 [00:01&lt;00:00, 334.13it/s]
Epoch 33: 100%|██████████| 378/378 [00:01&lt;00:00, 273.49it/s]
Epoch 34: 100%|██████████| 378/378 [00:01&lt;00:00, 317.19it/s]
Epoch 35: 100%|██████████| 378/378 [00:01&lt;00:00, 319.72it/s]
Epoch 36: 100%|██████████| 378/378 [00:01&lt;00:00, 335.90it/s]
Epoch 37: 100%|██████████| 378/378 [00:01&lt;00:00, 321.90it/s]
Epoch 38: 100%|██████████| 378/378 [00:01&lt;00:00, 314.41it/s]
Epoch 39: 100%|██████████| 378/378 [00:01&lt;00:00, 213.93it/s]
Epoch 40: 100%|██████████| 378/378 [00:01&lt;00:00, 203.79it/s]
Epoch 41: 100%|██████████| 378/378 [00:01&lt;00:00, 230.35it/s]
Epoch 42: 100%|██████████| 378/378 [00:01&lt;00:00, 204.78it/s]
Epoch 43: 100%|██████████| 378/378 [00:01&lt;00:00, 250.98it/s]
Epoch 44: 100%|██████████| 378/378 [00:01&lt;00:00, 291.40it/s]
Epoch 45: 100%|██████████| 378/378 [00:01&lt;00:00, 319.18it/s]
Epoch 46: 100%|██████████| 378/378 [00:01&lt;00:00, 265.43it/s]
Epoch 47: 100%|██████████| 378/378 [00:01&lt;00:00, 329.76it/s]
Epoch 48: 100%|██████████| 378/378 [00:01&lt;00:00, 303.32it/s]
Epoch 49: 100%|██████████| 378/378 [00:01&lt;00:00, 255.22it/s]
Epoch 50: 100%|██████████| 378/378 [00:01&lt;00:00, 261.57it/s]
Epoch 51: 100%|██████████| 378/378 [00:01&lt;00:00, 272.70it/s]
Epoch 52: 100%|██████████| 378/378 [00:01&lt;00:00, 248.19it/s]
Epoch 53: 100%|██████████| 378/378 [00:01&lt;00:00, 332.95it/s]
Epoch 54: 100%|██████████| 378/378 [00:01&lt;00:00, 315.46it/s]
Epoch 55: 100%|██████████| 378/378 [00:01&lt;00:00, 279.76it/s]
Epoch 56: 100%|██████████| 378/378 [00:02&lt;00:00, 174.70it/s]
Epoch 57: 100%|██████████| 378/378 [00:01&lt;00:00, 326.63it/s]
Epoch 58: 100%|██████████| 378/378 [00:01&lt;00:00, 343.54it/s]
Epoch 59: 100%|██████████| 378/378 [00:01&lt;00:00, 199.70it/s]
Epoch 60: 100%|██████████| 378/378 [00:01&lt;00:00, 221.06it/s]
Epoch 61: 100%|██████████| 378/378 [00:01&lt;00:00, 317.31it/s]
Epoch 62: 100%|██████████| 378/378 [00:01&lt;00:00, 264.31it/s]
Epoch 63: 100%|██████████| 378/378 [00:01&lt;00:00, 262.30it/s]
Epoch 64: 100%|██████████| 378/378 [00:01&lt;00:00, 313.63it/s]
Epoch 65: 100%|██████████| 378/378 [00:01&lt;00:00, 317.58it/s]
Epoch 66: 100%|██████████| 378/378 [00:01&lt;00:00, 297.35it/s]
Epoch 67: 100%|██████████| 378/378 [00:01&lt;00:00, 239.24it/s]
Epoch 68: 100%|██████████| 378/378 [00:01&lt;00:00, 314.15it/s]
Epoch 69: 100%|██████████| 378/378 [00:01&lt;00:00, 242.92it/s]
Epoch 70: 100%|██████████| 378/378 [00:01&lt;00:00, 319.18it/s]
Epoch 71: 100%|██████████| 378/378 [00:01&lt;00:00, 329.47it/s]
Epoch 72: 100%|██████████| 378/378 [00:01&lt;00:00, 317.31it/s]
Epoch 73: 100%|██████████| 378/378 [00:01&lt;00:00, 335.91it/s]
Epoch 74: 100%|██████████| 378/378 [00:01&lt;00:00, 284.60it/s]
Epoch 75: 100%|██████████| 378/378 [00:01&lt;00:00, 317.84it/s]
Epoch 76: 100%|██████████| 378/378 [00:01&lt;00:00, 323.28it/s]
Epoch 77: 100%|██████████| 378/378 [00:01&lt;00:00, 317.58it/s]
Epoch 78: 100%|██████████| 378/378 [00:01&lt;00:00, 317.31it/s]
Epoch 79: 100%|██████████| 378/378 [00:01&lt;00:00, 267.68it/s]
Epoch 80: 100%|██████████| 378/378 [00:01&lt;00:00, 337.71it/s]
Epoch 81: 100%|██████████| 378/378 [00:01&lt;00:00, 322.72it/s]
Epoch 82: 100%|██████████| 378/378 [00:01&lt;00:00, 314.15it/s]
Epoch 83: 100%|██████████| 378/378 [00:01&lt;00:00, 338.92it/s]
Epoch 84: 100%|██████████| 378/378 [00:01&lt;00:00, 265.43it/s]
Epoch 85: 100%|██████████| 378/378 [00:01&lt;00:00, 328.04it/s]
Epoch 86: 100%|██████████| 378/378 [00:01&lt;00:00, 329.18it/s]
Epoch 87: 100%|██████████| 378/378 [00:01&lt;00:00, 330.62it/s]
Epoch 88: 100%|██████████| 378/378 [00:01&lt;00:00, 338.91it/s]
Epoch 89: 100%|██████████| 378/378 [00:01&lt;00:00, 250.15it/s]
Epoch 90: 100%|██████████| 378/378 [00:01&lt;00:00, 300.66it/s]
Epoch 91: 100%|██████████| 378/378 [00:01&lt;00:00, 289.83it/s]
Epoch 92: 100%|██████████| 378/378 [00:01&lt;00:00, 321.35it/s]
Epoch 93: 100%|██████████| 378/378 [00:01&lt;00:00, 321.08it/s]
Epoch 94: 100%|██████████| 378/378 [00:01&lt;00:00, 256.60it/s]
Epoch 95: 100%|██████████| 378/378 [00:01&lt;00:00, 309.26it/s]
Epoch 96: 100%|██████████| 378/378 [00:01&lt;00:00, 332.95it/s]
Epoch 97: 100%|██████████| 378/378 [00:01&lt;00:00, 333.54it/s]
Epoch 98: 100%|██████████| 378/378 [00:01&lt;00:00, 295.04it/s]
Epoch 99: 100%|██████████| 378/378 [00:01&lt;00:00, 314.41it/s]
Epoch 100: 100%|██████████| 378/378 [00:01&lt;00:00, 334.72it/s]
</pre></div>
</div>
<img alt="../../../_images/fec298251009b3ef450656c7730ad08244e63fd9887dda0b0d019f088afdf81d.png" src="../../../_images/fec298251009b3ef450656c7730ad08244e63fd9887dda0b0d019f088afdf81d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Vector of &quot;&#39;Telegram&#39;&quot; word:
[ 1.55561541e-01  1.77020706e-01 -5.40811034e-03  3.59769057e-03
 -8.16132010e-03 -4.15956336e-02 -1.79394031e-02 -1.44513644e-01
  1.56769822e-01 -5.83205062e-05  1.55230251e-01  1.15323020e-02
  1.20502608e-01 -2.04556712e-01 -1.29421676e-01  3.21621670e-02
 -1.63679719e-01 -1.14871509e-01  8.62045380e-02 -5.56635456e-02
 -1.67371505e-01 -5.28203969e-02 -9.17762628e-02  1.08312141e-01
 -5.51253747e-02  1.67345727e-01  1.61171293e-01 -6.27636788e-03
  1.39057885e-01  1.83056904e-01  2.28870038e-01 -1.28071171e-01
 -1.26117661e-01  4.29829807e-02 -2.03594756e-01 -1.60113889e-01
 -2.32977882e-02  1.37207303e-02 -2.25264920e-01  2.30003619e-01
  1.33797845e-01 -6.34702484e-02 -1.32517611e-01  5.88101981e-02
  2.36643770e-01  1.24257856e-01 -3.05104777e-01 -2.45094159e-02
  3.45571410e-02 -4.56085027e-02], word_id:176
</pre></div>
</div>
<img alt="../../../_images/5f9d75e9849fd555877d0a006f14f7f712fdc6db5f2925be1016b01a14df2f6a.png" src="../../../_images/5f9d75e9849fd555877d0a006f14f7f712fdc6db5f2925be1016b01a14df2f6a.png" />
</div>
</div>
</section>
<section id="why-glove-is-effective">
<h2>Why GloVe is Effective ?<a class="headerlink" href="#why-glove-is-effective" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Global Information</strong>: GloVe leverages the <strong>global co-occurrence statistics</strong> of the entire corpus, meaning it takes into account all the word pairs and their relationships across the whole text.</p></li>
<li><p><strong>Semantic Vectors</strong>: The resulting word embeddings capture semantic relationships, meaning that words like “king” and “queen” will have similar vector representations because of their similar usage contexts.</p></li>
<li><p><strong>Linear Relationships</strong>: One of GloVe’s key features is its ability to represent linear relationships between words. For example, it captures analogies like:
vector(“king”) - vector(“man”) + vector(“woman”) ≈ vector(“queen”) This means that GloVe can model relationships between words in a way that reflects their real-world meanings.</p></li>
<li><p><strong>Efficient Representation</strong>: Words with similar meanings or usage patterns will have similar vectors, which is useful for downstream NLP tasks.</p></li>
</ul>
</section>
<section id="applications-for-glove">
<h2>Applications for GloVe:<a class="headerlink" href="#applications-for-glove" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Text Analysis</strong>: Used in NLP tasks to capture word meanings and relationships for tasks like sentiment analysis or text classification.</p></li>
<li><p><strong>Recommendation Systems</strong>: Helps find relationships between words or items for smarter recommendations.</p></li>
<li><p><strong>Machine Translation</strong>: Improves machine translation systems by providing better word representations based on their meaning.</p></li>
</ul>
</section>
<section id="difference-between-glove-and-word2vec">
<h2>Difference Between GloVe and Word2Vec:<a class="headerlink" href="#difference-between-glove-and-word2vec" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>GloVe</strong> focuses on the global co-occurrence of words in a corpus and uses a matrix to capture these relationships. <strong>Word2Vec</strong>, on the other hand, is based on local context windows around words and predicts word occurrences based on nearby words.</p></li>
<li><p>GloVe generally excels at learning more <strong>general semantic relationships</strong> between words, whereas Word2Vec focuses more on <strong>predictive</strong> word modeling.</p></li>
</ul>
</section>
<section id="conclusion">
<h2>Conclusion:<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p><strong>GloVe</strong> is a powerful word embedding model that learns to represent words as vectors by analyzing how often they co-occur with other words in a corpus. These embeddings capture both the meaning and relationships between words, making <strong>GloVe</strong> extremely useful in various NLP tasks. Its ability to encode semantic relationships, including analogies, makes it one of the leading methods for generating word embeddings, alongside Word2Vec.</p>
</section>
<section id="refrences">
<h2>Refrences:<a class="headerlink" href="#refrences" title="Link to this heading">#</a></h2>
<p>1: <a class="reference external" href="https://aclanthology.org/D14-1162.pdf">Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. “Glove: Global Vectors for Word Representation.”</a></p>
<p>2: <a class="reference external" href="https://nlp.stanford.edu/projects/glove/">Stanford NLP GloVe Project</a></p>
<p>3: <a class="reference external" href="https://wandb.ai/authors/embeddings-2/reports/An-Introduction-to-the-Global-Vectors-GloVe-Algorithm--VmlldzozNDg2NTQ">An Introduction to the Global Vectors (GloVe) Algorithm</a></p>
<p>4: <a class="reference external" href="https://www.scaler.com/topics/nlp/glove-embeddings/">GloVe in NLP</a></p>
<p>5: <a class="reference external" href="https://rare-technologies.com/making-sense-of-word2vec/">Making sense of word2vec</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./PR\StudentEffort\GloVe"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Chernoff/ChernoffEsri.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chernoff Faces in ESRI</p>
      </div>
    </a>
    <a class="right-next"
       href="../LinkageClustering1/linkageclustering2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Linkage Clustering Algorithm</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-glove">What is GloVe?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-we-need-glove">Why Do We Need GloVe?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-does-glove-work">How Does GloVe Work?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-co-occurrence-matrix">1: Building a Co-occurrence Matrix:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#capturing-relationships-between-words">2: Capturing Relationships Between Words:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-word-vectors">3: Learning Word Vectors:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-with-a-loss-function">4: Optimization with a Loss Function:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-vectors-as-final-output">5: Word Vectors as Final Output:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practice-with-code">Practice with code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#get-posts-from-telegram">Get posts from Telegram:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#import-required-libraries">1. Import Required Libraries:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-prepare-data-and-build-the-co-occurrence-matrix">2. Step 1: Prepare Data and Build the Co-occurrence Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#glove-loss-function">3. GloVe Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-glove-model">4. Training the GloVe Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#all-code-sections-in-one">All code sections in one:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-glove-is-effective">Why GloVe is Effective ?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-for-glove">Applications for GloVe:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-glove-and-word2vec">Difference Between GloVe and Word2Vec:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#refrences">Refrences:</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr.Hadi Sadoghi Yazdi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024 Pattern Recognition Lab.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>